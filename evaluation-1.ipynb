{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":4,"language_info":{"name":"python","version":"3.6.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3.6.8 64-bit ('base': conda)"},"interpreter":{"hash":"98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"},"colab":{"name":"evaluation-1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"uhLSxykOZbx7","outputId":"91a684a4-9e88-474c-ccac-9103f5f54954"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Sep 29 06:32:23 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-PCIE...  Off  | 00000000:18:00.0 Off |                    0 |\n","| N/A   43C    P0    42W / 250W |   1181MiB / 32510MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","|   1  Tesla V100-PCIE...  Off  | 00000000:AF:00.0 Off |                    0 |\n","| N/A   35C    P0    24W / 250W |      4MiB / 32510MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"KXfh11sKZbyJ","executionInfo":{"status":"ok","timestamp":1633256529622,"user_tz":-540,"elapsed":880,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["from argparse import Namespace\n","import logging\n","opt = {\n","    \"batch_size\": 4,\n","    \"num_workers\": 4,\n","    \"lr\": 1e-4,\n","    \"max_epochs\": 10,\n","    \"warmup_ratio\": 0.2,\n","    \"print_step\": 100,\n","    \"save_path\": \"drive/MyDrive/model_weights\",\n","} \n","args = Namespace(**opt)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"FkuHXYDiZbyN","executionInfo":{"status":"ok","timestamp":1633256533552,"user_tz":-540,"elapsed":1904,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["import json\n","path = \"drive/MyDrive/\"\n","train_file = path + \"train.json\"\n","with open(train_file, \"r\") as f:\n","    TRAIN_DATA = json.load(f)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8aRzXcOZbyO","executionInfo":{"status":"ok","timestamp":1633256537806,"user_tz":-540,"elapsed":872,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["import json\n","path = \"drive/MyDrive/\"\n","test_file = path + \"test.json\"\n","with open(test_file, \"r\") as f:\n","    TEST_DATA = json.load(f)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"so7btq-Jbc7y","executionInfo":{"status":"ok","timestamp":1633256622467,"user_tz":-540,"elapsed":83185,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"fe7dd18e-37c4-47c0-942f-e3aae41d7d0a"},"source":["!pip install git+https://github.com/SKT-AI/KoBART#egg=kobart"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kobart\n","  Cloning https://github.com/SKT-AI/KoBART to /tmp/pip-install-1axfx_r3/kobart_e6663006222c413fbeb45cb7639de8e8\n","  Running command git clone -q https://github.com/SKT-AI/KoBART /tmp/pip-install-1axfx_r3/kobart_e6663006222c413fbeb45cb7639de8e8\n","Collecting transformers==4.3.3\n","  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.9 MB 4.0 MB/s \n","\u001b[?25hCollecting torch==1.7.1\n","  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 776.8 MB 15 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->kobart) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->kobart) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart) (4.8.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->kobart) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->kobart) (3.5.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.3.3->kobart) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.3.3->kobart) (2.10)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.3.3->kobart) (1.15.0)\n","Building wheels for collected packages: kobart\n","  Building wheel for kobart (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobart: filename=kobart-0.4-py3-none-any.whl size=8538 sha256=fb52a693e2bfe94dc3bdbd7c297d084c108254a7090fec8d4d528c9a956b1663\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ommlj1yd/wheels/6e/55/c4/bd4fede223bc304089ac8da2a2099a69db3fcd4b0e853383f5\n","Successfully built kobart\n","Installing collected packages: tokenizers, sacremoses, transformers, torch, kobart\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n","Successfully installed kobart-0.4 sacremoses-0.0.46 tokenizers-0.10.3 torch-1.7.1 transformers-4.3.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMP9k7-UZbyP","executionInfo":{"status":"ok","timestamp":1633256639260,"user_tz":-540,"elapsed":1336,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"105caf6b-f88c-45ff-cc12-3800deb5004a"},"source":["from kobart import get_kobart_tokenizer\n","kobart_tokenizer = get_kobart_tokenizer()\n","kobart_tokenizer.tokenize(\"ÏïàÎÖïÌïòÏÑ∏Ïöî. ÌïúÍµ≠Ïñ¥ BART ÏûÖÎãàÎã§.ü§£:)l^o\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\r[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà]\n"]},{"output_type":"execute_result","data":{"text/plain":["['‚ñÅÏïàÎÖïÌïò', 'ÏÑ∏Ïöî.', '‚ñÅÌïúÍµ≠Ïñ¥', '‚ñÅB', 'A', 'R', 'T', '‚ñÅÏûÖ', 'ÎãàÎã§.', 'ü§£', ':)', 'l^o']"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9PzBlzcdZbyR","executionInfo":{"status":"ok","timestamp":1633256769465,"user_tz":-540,"elapsed":127829,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"cff72a0a-ff90-4b99-ed68-4e393a540741"},"source":["from transformers import BartModel, BartForConditionalGeneration\n","from kobart import get_pytorch_kobart_model, get_kobart_tokenizer\n","kobart_tokenizer = get_kobart_tokenizer()\n","model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model())#BartModel.from_pretrained(get_pytorch_kobart_model())\n","inputs = kobart_tokenizer(['ÏïàÎÖïÌïòÏÑ∏Ïöî.'], return_tensors='pt')\n","model(inputs['input_ids'])"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n","[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà]\n"]},{"output_type":"execute_result","data":{"text/plain":["Seq2SeqLMOutput([('logits',\n","                  tensor([[[-3.1152,  5.6895, -8.4704,  ..., -7.6067, -4.6915, -4.2773],\n","                           [-6.7131,  4.5574, -7.6131,  ..., -6.8429, -5.2066, -6.7749]]],\n","                         grad_fn=<AddBackward0>)),\n","                 ('past_key_values',\n","                  ((tensor([[[[-9.7980e-02, -6.6584e-01, -1.8089e+00,  ...,  9.6023e-01,\n","                               -1.8818e-01, -1.3252e+00],\n","                              [-6.2507e-01,  5.1009e-01, -7.4878e-01,  ...,  8.6230e-01,\n","                                1.5722e-01, -6.0267e-01]],\n","                    \n","                             [[ 5.4597e-01, -2.3990e-01,  1.5901e+00,  ...,  4.3655e-01,\n","                                7.9514e-01,  8.9880e-02],\n","                              [-1.7327e-01, -6.3167e-01,  4.5152e-02,  ..., -1.4111e-01,\n","                                1.8678e-01, -1.2081e-01]],\n","                    \n","                             [[ 1.4621e+00,  1.8980e+00, -7.6696e-01,  ...,  1.5695e+00,\n","                                6.7921e-02, -3.9372e-01],\n","                              [-4.1204e-02,  1.7132e+00, -1.1863e+00,  ..., -2.2272e-01,\n","                                9.8310e-02,  8.1729e-01]],\n","                    \n","                             ...,\n","                    \n","                             [[ 4.8868e-01,  1.2633e+00, -1.1658e-01,  ..., -3.1989e-01,\n","                                1.2202e+00, -7.9021e-02],\n","                              [-8.4946e-01,  8.9379e-02, -1.0224e+00,  ...,  3.3125e-01,\n","                               -2.5262e-01,  5.0875e-01]],\n","                    \n","                             [[ 1.5854e+00,  3.2461e-01,  3.0826e+00,  ..., -1.6728e+00,\n","                                1.2071e+00, -3.5671e-01],\n","                              [ 5.5400e-02, -9.2782e-01, -2.3054e-03,  ..., -6.1646e-01,\n","                                1.0880e+00,  2.8645e-01]],\n","                    \n","                             [[ 8.7081e-01, -4.6088e-01, -2.8388e+00,  ...,  1.6038e+00,\n","                               -1.0963e+00, -1.8732e-01],\n","                              [ 4.5471e-01, -3.1087e-02, -2.4484e+00,  ...,  1.9392e+00,\n","                               -4.0694e-01, -1.9906e-01]]]], grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.2187,  1.3322, -0.0016,  ..., -0.1200, -0.0395,  0.0971],\n","                              [-0.2722, -0.0590,  0.4620,  ...,  0.1822, -0.0171, -0.2176]],\n","                    \n","                             [[ 0.1439,  0.0074,  0.0249,  ...,  0.2148, -0.5016,  0.1263],\n","                              [ 0.3625, -0.3192, -0.2254,  ...,  0.6312,  0.1061,  0.3506]],\n","                    \n","                             [[-0.0862, -0.0073, -0.0479,  ...,  0.0110,  0.0198,  0.1909],\n","                              [-0.4622, -0.4537, -0.6060,  ...,  0.5620,  1.3319,  0.0989]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.0868, -0.1329,  0.1862,  ..., -0.0489, -0.0084,  0.0151],\n","                              [-0.4065,  0.4082,  0.7682,  ..., -0.0909,  0.1701,  0.0145]],\n","                    \n","                             [[ 0.1256,  0.1170,  0.0912,  ...,  0.0623, -0.0574,  0.0611],\n","                              [-0.2664, -0.4485,  0.1439,  ...,  0.2324,  0.3832, -1.0943]],\n","                    \n","                             [[ 0.0702,  0.0227,  0.0311,  ..., -0.0203,  0.0602,  0.0033],\n","                              [-0.3197,  0.4879,  0.1972,  ..., -0.3241,  0.1762,  0.5655]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[-1.0648, -2.5643, -1.2208,  ...,  1.4609,  1.0088,  0.8616],\n","                              [-1.3031, -2.4746, -1.2874,  ...,  1.4641,  0.6007,  0.5663]],\n","                    \n","                             [[-0.9957, -1.4633, -0.6104,  ..., -0.0807,  0.6639,  1.1657],\n","                              [-0.8524, -2.1023, -0.3089,  ...,  0.1747,  0.9409,  0.8996]],\n","                    \n","                             [[ 1.7265, -0.0293, -0.3755,  ..., -0.6951,  0.4730,  0.3141],\n","                              [ 1.5839, -0.6262, -0.5320,  ...,  0.2295,  0.5922,  0.6125]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.1965, -0.4015,  1.1312,  ..., -0.5016, -0.1073,  0.0549],\n","                              [-0.5866, -0.6739,  1.0961,  ..., -0.3082, -0.1296,  0.0126]],\n","                    \n","                             [[-0.0225,  0.6815, -1.6006,  ...,  1.7747, -0.4324, -1.2341],\n","                              [ 0.2012,  0.2133, -2.0224,  ...,  1.0445, -0.3429, -1.1153]],\n","                    \n","                             [[-0.4898, -0.2916,  0.1036,  ..., -1.1657, -2.0047, -0.5035],\n","                              [ 0.2014,  0.0172, -0.2052,  ..., -1.1187, -2.9760, -0.2173]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.2822, -0.1430, -0.0214,  ...,  0.0815,  0.1900, -0.2706],\n","                              [ 0.0435, -0.3802, -0.3064,  ...,  0.5159,  0.1527, -0.2039]],\n","                    \n","                             [[-0.8001,  0.0466,  1.0855,  ..., -0.2635, -0.2926,  0.3927],\n","                              [-0.3446, -0.6481,  0.5623,  ...,  0.3295,  0.6792,  0.4060]],\n","                    \n","                             [[-0.8864, -0.0462, -0.4937,  ..., -1.2180,  0.5027,  0.1991],\n","                              [-0.8240, -0.4198,  0.1187,  ..., -0.3042,  0.6595, -0.1653]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.3499,  0.7639,  0.0130,  ...,  0.3620,  0.4275, -0.6412],\n","                              [-0.1910,  0.5114, -0.0352,  ...,  0.3060,  0.2019, -0.4844]],\n","                    \n","                             [[ 0.2417,  0.1567,  0.2082,  ...,  0.1640, -0.1767, -0.1738],\n","                              [ 0.1304, -0.0716, -0.1840,  ...,  0.3307,  0.1039,  0.1808]],\n","                    \n","                             [[-0.4749, -0.9211,  1.0276,  ..., -0.3349, -0.2668, -0.2143],\n","                              [ 0.0051, -0.7191,  0.6315,  ..., -0.2618,  0.0611, -0.1337]]]],\n","                           grad_fn=<CopyBackwards>)),\n","                   (tensor([[[[ 0.0568,  0.1593,  0.3356,  ..., -0.0771, -0.1446, -0.1562],\n","                              [ 1.6254, -1.5403,  1.2852,  ...,  0.3466, -1.0204, -1.6762]],\n","                    \n","                             [[ 0.2014, -0.2892, -0.4829,  ...,  0.2817, -0.1413,  1.5805],\n","                              [ 0.6554,  1.6124,  0.4492,  ...,  0.3675,  1.0584, -3.6320]],\n","                    \n","                             [[-0.1167,  0.6492, -0.5715,  ...,  0.0990, -1.3751, -0.3157],\n","                              [ 0.5295, -2.8552,  1.0669,  ...,  0.8807,  2.6310, -0.9037]],\n","                    \n","                             ...,\n","                    \n","                             [[ 0.0606,  0.1003,  0.1334,  ...,  0.0648,  0.0886,  1.1766],\n","                              [ 0.9016, -1.1139,  1.2164,  ...,  0.0885,  0.5449, -1.5874]],\n","                    \n","                             [[ 0.1461,  0.1861,  0.0330,  ..., -0.0966, -0.3876,  0.2000],\n","                              [-0.4877,  0.6808,  0.8141,  ...,  1.1511, -1.0540, -0.7516]],\n","                    \n","                             [[ 0.4198,  0.1532,  0.4183,  ..., -0.1995, -0.0194,  0.3649],\n","                              [ 1.9049,  0.4632, -1.9892,  ...,  0.2458,  0.5797, -0.5118]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 1.5379e-02,  4.6779e-02,  2.3209e-02,  ..., -3.6807e-03,\n","                               -6.6380e-02,  8.8298e-04],\n","                              [ 3.3722e-01,  5.9773e-01, -9.7631e-01,  ..., -6.7000e-01,\n","                               -8.6936e-01, -1.0744e+00]],\n","                    \n","                             [[-8.2674e-03, -2.8380e-02, -3.8986e-02,  ...,  1.9672e-02,\n","                                2.6157e-03,  2.0187e-03],\n","                              [ 4.2856e-01,  1.3611e+00,  4.8732e-01,  ..., -5.9338e-02,\n","                               -1.1926e-01, -4.2580e-02]],\n","                    \n","                             [[ 6.0655e-02, -1.8253e-02, -1.5229e-02,  ..., -1.6663e-02,\n","                                8.4880e-03, -4.8301e-02],\n","                              [-1.0497e-01, -8.1324e-02,  3.3243e-01,  ...,  3.5059e-01,\n","                               -7.1202e-02,  1.6472e-02]],\n","                    \n","                             ...,\n","                    \n","                             [[ 3.6912e-02, -6.7970e-02, -8.0440e-02,  ..., -9.4137e-02,\n","                                3.8142e-03,  7.8197e-02],\n","                              [-2.4057e-01,  2.6778e-03,  7.9480e-01,  ...,  2.9896e-01,\n","                                7.9629e-01,  9.2801e-01]],\n","                    \n","                             [[ 1.9845e-02,  4.9133e-03, -3.3145e-02,  ...,  7.2793e-02,\n","                                5.9300e-02, -5.7760e-02],\n","                              [-3.6504e-01,  5.4651e-01, -4.3528e-02,  ..., -3.2015e-01,\n","                                7.9082e-01, -9.7559e-02]],\n","                    \n","                             [[ 3.4483e-02, -1.2532e-02,  1.5040e-02,  ...,  1.7609e-02,\n","                               -2.3566e-02, -2.2959e-02],\n","                              [-1.1245e+00, -6.8237e-01,  1.0025e-01,  ..., -2.7405e-01,\n","                               -5.1046e-01, -1.9640e-01]]]], grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 2.3286e+00, -4.2949e-02,  3.0110e+00,  ...,  1.0627e+00,\n","                               -9.1236e-01,  2.6603e+00],\n","                              [ 3.0073e+00, -1.5674e-01,  2.8979e+00,  ...,  9.7826e-01,\n","                               -5.3162e-01,  3.0233e+00]],\n","                    \n","                             [[ 1.7130e+00, -2.9926e+00,  1.8776e+00,  ...,  7.5415e-01,\n","                               -8.7124e-01, -4.8129e-01],\n","                              [ 2.5121e+00, -3.2266e+00,  2.2682e+00,  ...,  4.4046e-01,\n","                               -5.1476e-01, -5.2341e-01]],\n","                    \n","                             [[-8.1486e-01, -9.5213e-01, -8.3411e-04,  ...,  1.5024e+00,\n","                               -5.7569e-01,  1.9130e-01],\n","                              [-8.1358e-01, -1.2385e+00,  9.3572e-01,  ...,  1.1406e+00,\n","                               -9.5044e-01, -4.8016e-01]],\n","                    \n","                             ...,\n","                    \n","                             [[ 8.1763e-01, -9.2276e-01,  1.5260e+00,  ...,  2.9563e-02,\n","                                1.5475e-02, -8.2439e-01],\n","                              [ 1.4520e-02, -1.5225e+00,  1.9413e+00,  ..., -3.6908e-01,\n","                                5.3651e-01, -2.1469e-01]],\n","                    \n","                             [[-1.0017e+00, -5.5066e-01, -1.8923e+00,  ..., -5.8160e-01,\n","                                4.2548e-01, -6.7959e-01],\n","                              [-5.8291e-01, -8.2588e-01, -2.0550e+00,  ..., -2.2966e-01,\n","                                2.4398e-02, -2.6139e-01]],\n","                    \n","                             [[-1.4829e+00, -8.8995e-01,  9.4026e-01,  ...,  1.4175e+00,\n","                               -3.9160e-01, -9.2237e-01],\n","                              [-1.0111e+00, -1.1450e+00,  1.1993e+00,  ...,  2.0617e+00,\n","                               -5.9144e-01, -1.3860e+00]]]], grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.1935, -0.1730,  0.3934,  ..., -0.0840,  0.2339,  0.1091],\n","                              [-0.0569, -0.3551,  0.3823,  ...,  0.0197, -0.0043, -0.0436]],\n","                    \n","                             [[ 0.2364,  0.4606,  0.5622,  ...,  0.4819,  0.1865,  0.6264],\n","                              [ 0.5973,  0.2811,  0.2784,  ...,  0.1489, -0.4533,  0.4468]],\n","                    \n","                             [[ 0.4116,  0.4325, -0.3306,  ..., -0.7509,  0.2645, -0.1624],\n","                              [ 0.8045,  0.3654, -0.4785,  ..., -0.7986, -0.0484, -0.1889]],\n","                    \n","                             ...,\n","                    \n","                             [[ 0.1706, -1.0074,  0.2970,  ...,  0.4921,  0.5458,  0.1225],\n","                              [ 0.3865, -1.1976, -0.2150,  ...,  0.6561,  0.4510,  0.1755]],\n","                    \n","                             [[ 0.0047, -0.7317,  0.3213,  ...,  0.5871, -0.2654, -0.4047],\n","                              [-0.1921, -0.4592,  0.0943,  ...,  0.3975, -0.2417, -0.3156]],\n","                    \n","                             [[-0.1002, -0.3230,  0.6674,  ..., -0.2355, -0.6963, -0.3525],\n","                              [-0.1739, -0.4883,  0.4101,  ..., -0.2514, -0.6257, -0.6858]]]],\n","                           grad_fn=<CopyBackwards>)),\n","                   (tensor([[[[-0.1980, -0.8728,  0.6663,  ...,  0.2215,  0.3865, -0.0239],\n","                              [ 0.7417,  3.5312, -0.8480,  ..., -0.0536, -0.7790, -0.2229]],\n","                    \n","                             [[ 0.3768, -0.2689, -0.0428,  ...,  0.1046, -0.1428, -0.9039],\n","                              [ 0.0478,  2.5229, -0.2297,  ..., -0.2463,  3.8656,  4.1837]],\n","                    \n","                             [[-0.0777,  0.5079,  0.0822,  ...,  0.0193, -0.5585,  0.1365],\n","                              [ 0.6972, -2.6046,  1.8231,  ..., -1.2138,  2.4488,  0.6540]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.4664,  0.2169,  0.0277,  ...,  1.1934,  0.6856,  0.1670],\n","                              [ 0.6041,  0.9994,  0.1424,  ..., -1.8193, -1.1613, -0.5548]],\n","                    \n","                             [[ 0.0759,  0.1255, -0.0151,  ...,  0.0307,  0.1052, -0.6455],\n","                              [ 0.6701,  0.7716,  0.2974,  ..., -0.7394,  0.5873,  3.0509]],\n","                    \n","                             [[ 0.1543,  0.2131, -0.0718,  ...,  0.0975, -0.0069, -0.3904],\n","                              [-0.5077, -1.8357,  2.1244,  ...,  0.3969,  1.3626, -0.0225]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 2.9269e-02,  1.1764e-01, -1.2732e-02,  ..., -8.6455e-02,\n","                                1.2252e-01,  6.7036e-03],\n","                              [ 3.9763e-01, -2.9863e-01, -4.3627e-01,  ..., -5.6594e-02,\n","                               -2.9132e-01, -6.3776e-01]],\n","                    \n","                             [[ 1.6335e-02, -2.4424e-02, -4.8432e-03,  ..., -5.6251e-02,\n","                               -6.8835e-02,  1.2608e-02],\n","                              [ 3.5408e-01,  6.1424e-01,  3.5653e-01,  ..., -3.0892e-02,\n","                                7.4476e-02,  2.0799e-02]],\n","                    \n","                             [[ 2.5243e-02,  1.0407e-02, -4.8344e-02,  ...,  6.4945e-03,\n","                                3.9796e-04,  1.2100e-01],\n","                              [ 7.1725e-01, -1.8262e-01, -3.0229e-01,  ..., -4.4057e-01,\n","                               -3.8582e-02, -2.3157e-01]],\n","                    \n","                             ...,\n","                    \n","                             [[ 9.2560e-03,  1.4655e-02,  3.4054e-02,  ...,  9.6428e-03,\n","                               -6.3913e-03,  2.7569e-02],\n","                              [ 4.2214e-01,  3.7137e-01,  2.3890e-01,  ..., -1.7630e-01,\n","                                9.0582e-01,  1.0196e-01]],\n","                    \n","                             [[ 3.1055e-03,  1.0484e-02, -4.7095e-03,  ...,  4.8638e-02,\n","                               -1.5250e-02, -7.0406e-02],\n","                              [ 9.7426e-02,  2.6014e-01,  3.1176e-01,  ..., -4.8579e-01,\n","                                9.3070e-01, -1.1125e-01]],\n","                    \n","                             [[ 2.8621e-02, -2.8968e-03, -3.1328e-02,  ...,  2.5224e-02,\n","                                1.8680e-02, -4.3578e-02],\n","                              [ 3.0150e-01, -1.9468e-01, -1.7805e-01,  ...,  5.1854e-01,\n","                               -3.4874e-02,  9.8428e-02]]]], grad_fn=<CopyBackwards>),\n","                    tensor([[[[-1.7399,  1.5544,  0.8420,  ...,  0.1949,  0.3739, -0.4898],\n","                              [-1.6240,  1.3219,  0.9978,  ..., -0.4160, -0.1783,  0.3793]],\n","                    \n","                             [[-0.2877, -0.3362, -0.3745,  ...,  0.3365,  0.1496, -1.2037],\n","                              [-0.2730, -0.1071, -0.1413,  ...,  0.3996, -0.1407, -1.1605]],\n","                    \n","                             [[ 1.4108, -0.6566,  1.7061,  ...,  1.4992,  0.5674, -0.9317],\n","                              [ 1.7853, -1.0445,  1.7326,  ...,  1.7643,  0.5169, -1.0316]],\n","                    \n","                             ...,\n","                    \n","                             [[-1.7319,  3.2136,  1.1013,  ..., -0.8693, -0.2972, -1.2679],\n","                              [-2.0636,  3.6187,  0.9261,  ..., -0.9856, -0.3694, -1.0883]],\n","                    \n","                             [[-0.9236,  0.7800, -0.0765,  ...,  1.6758,  1.2948,  0.3508],\n","                              [-0.6022,  0.7458, -0.1418,  ...,  2.1779,  1.1909,  0.1315]],\n","                    \n","                             [[ 0.4240,  0.0391, -1.3894,  ..., -1.0823, -0.4126,  0.9783],\n","                              [ 0.5731, -0.2723, -1.8803,  ..., -1.2079, -1.0119,  0.5113]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.0985, -0.6352, -0.0868,  ...,  0.0363,  0.0543, -0.3238],\n","                              [-0.2378, -0.1665, -0.3516,  ...,  0.3921, -0.2744, -0.3039]],\n","                    \n","                             [[ 0.8450,  0.2317,  0.6335,  ...,  0.5318, -0.0949,  0.1750],\n","                              [ 0.5121,  0.0876,  0.5792,  ..., -0.0148, -0.4605,  0.2020]],\n","                    \n","                             [[-0.2443, -0.0378,  0.2317,  ...,  0.0219, -0.1216,  0.0395],\n","                              [-0.4156,  0.0576,  0.1678,  ...,  0.0501, -0.3476, -0.2093]],\n","                    \n","                             ...,\n","                    \n","                             [[ 0.1073,  0.2830,  0.1495,  ..., -1.0262,  0.5416,  0.5043],\n","                              [ 0.2258,  0.0643, -0.1481,  ..., -1.0380,  0.3420,  0.5458]],\n","                    \n","                             [[-0.1796, -0.4815,  0.2412,  ..., -0.1130,  0.5764,  0.0777],\n","                              [-0.2803, -0.4700,  0.0848,  ...,  0.2658,  0.4753,  0.1039]],\n","                    \n","                             [[ 0.5494,  0.6024, -0.6296,  ...,  0.1007,  0.8262, -0.1736],\n","                              [ 0.3254,  0.5532, -0.1605,  ..., -0.2396,  0.2754,  0.1460]]]],\n","                           grad_fn=<CopyBackwards>)),\n","                   (tensor([[[[ 0.8659,  1.2230, -0.0036,  ..., -0.1768,  1.2656,  1.3975],\n","                              [-2.4391, -1.6445,  1.7410,  ..., -1.8302, -2.0103, -1.7548]],\n","                    \n","                             [[ 0.4183,  0.5536,  0.7881,  ..., -0.2234,  0.4811, -0.0375],\n","                              [-1.6890, -0.3787, -1.0577,  ..., -0.8861, -1.5151, -0.2258]],\n","                    \n","                             [[-0.5553, -1.0096,  0.1065,  ..., -0.4831,  1.4737, -0.0735],\n","                              [ 0.7138,  0.3943,  0.3157,  ...,  0.2931, -0.2829,  0.3843]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.6875,  0.4129, -0.7369,  ..., -1.1018, -0.7937,  0.5081],\n","                              [ 1.8270,  0.4463, -1.1159,  ...,  0.7450,  1.0975,  0.1329]],\n","                    \n","                             [[ 0.2528,  0.2051,  0.2412,  ...,  0.1542,  0.5065, -0.0168],\n","                              [ 0.0560,  1.4332,  0.3786,  ...,  0.1777, -0.5803,  0.0421]],\n","                    \n","                             [[-0.2057,  0.4577,  0.8795,  ..., -0.3249, -0.0460,  0.9419],\n","                              [-1.3328,  0.4214, -0.5938,  ..., -0.5810,  0.0759, -0.4099]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[-4.0518e-02, -5.9250e-02, -1.6183e-02,  ..., -8.3797e-04,\n","                               -3.3078e-02,  7.6099e-02],\n","                              [-4.3447e-01, -1.9747e-01, -4.3507e-01,  ..., -4.8681e-01,\n","                               -2.7236e-01, -8.4326e-02]],\n","                    \n","                             [[-1.4299e-01,  1.0976e-01, -3.2061e-02,  ..., -7.9136e-02,\n","                               -6.2019e-02,  1.1654e-03],\n","                              [ 5.5592e-01, -4.1032e-02,  1.5685e-01,  ...,  4.7759e-01,\n","                                4.6286e-01,  1.3250e-01]],\n","                    \n","                             [[-1.0311e-02, -3.4038e-02, -1.5415e-01,  ...,  2.3261e-02,\n","                               -1.4703e-02,  2.4091e-02],\n","                              [-8.1498e-01, -3.5524e-01,  3.3235e-02,  ...,  2.5945e-01,\n","                                5.5899e-02,  1.0831e+00]],\n","                    \n","                             ...,\n","                    \n","                             [[-1.8605e-02,  5.5119e-02,  2.7359e-03,  ..., -2.4560e-02,\n","                                6.2882e-03,  5.5261e-03],\n","                              [ 1.2290e-01, -4.1711e-01, -3.5411e-02,  ..., -2.1633e-01,\n","                               -4.8053e-01,  9.0853e-02]],\n","                    \n","                             [[-8.3875e-04,  6.2181e-02, -3.9761e-02,  ...,  5.1470e-02,\n","                                7.0819e-02,  8.0596e-03],\n","                              [ 5.9446e-02,  5.7503e-01, -7.6640e-01,  ...,  4.2502e-03,\n","                               -7.7809e-02,  9.4069e-02]],\n","                    \n","                             [[ 7.7253e-02,  7.0009e-02, -1.6194e-02,  ...,  2.5476e-02,\n","                               -8.1933e-03,  2.2595e-02],\n","                              [ 1.1499e-01, -3.9242e-01,  7.6922e-01,  ...,  2.9297e-01,\n","                                8.2074e-01,  6.4681e-01]]]], grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 2.0849, -0.0636,  0.5000,  ...,  0.9966,  1.7627,  1.5514],\n","                              [ 1.7876, -0.7635,  1.6988,  ...,  2.0722,  1.4739,  1.1660]],\n","                    \n","                             [[-0.8371,  0.9337,  0.7837,  ...,  0.0498,  1.6516,  0.1707],\n","                              [-0.5368,  1.0880,  0.5653,  ..., -0.0634,  1.3486, -0.6582]],\n","                    \n","                             [[-0.0912,  0.6096, -0.6076,  ...,  0.7558, -0.0126, -1.5131],\n","                              [-0.2230,  0.5867, -0.7267,  ...,  0.8867, -0.1216, -1.8096]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.6766,  0.6220,  1.5134,  ..., -0.1829,  0.0215,  1.1120],\n","                              [-0.8275,  0.6928,  1.6118,  ..., -0.2364,  0.0025,  1.4436]],\n","                    \n","                             [[ 1.1364,  0.0790, -0.3696,  ...,  0.2541,  0.9125, -0.5037],\n","                              [ 1.5442,  0.0934, -0.4613,  ...,  0.0754,  0.0034, -0.9217]],\n","                    \n","                             [[ 1.2640, -0.4548, -0.5475,  ...,  0.5674, -0.4214, -1.0081],\n","                              [ 1.2149, -0.7560, -0.2841,  ...,  0.4172, -0.3426, -0.9019]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[-0.0386, -0.1903,  0.1470,  ..., -0.3462, -0.1094, -0.1254],\n","                              [-0.0886,  0.0395,  0.0272,  ...,  0.0271, -0.3885,  0.0461]],\n","                    \n","                             [[ 0.1720, -0.3733, -0.0356,  ...,  0.0848,  0.4297,  0.5137],\n","                              [ 0.2865, -0.2505, -0.2307,  ..., -0.2456,  0.3889,  0.3922]],\n","                    \n","                             [[-0.5288, -0.7187,  0.3537,  ..., -0.7664,  0.2124,  0.3075],\n","                              [-0.3642, -0.0657,  0.0399,  ..., -0.5451,  0.2110,  0.1761]],\n","                    \n","                             ...,\n","                    \n","                             [[ 0.1834, -0.7011,  0.8361,  ...,  0.3994, -0.3654, -0.3145],\n","                              [ 0.2181, -0.7129,  0.8148,  ...,  0.1566,  0.0218,  0.0515]],\n","                    \n","                             [[-0.3867, -0.7703, -0.4015,  ..., -0.3819, -0.8259,  0.0101],\n","                              [ 0.2124,  0.1236, -0.8350,  ...,  0.3556, -1.1067, -0.0330]],\n","                    \n","                             [[-0.1518, -0.0204,  0.3507,  ..., -0.0252, -0.2174,  0.3534],\n","                              [ 0.2348, -0.1401,  0.4585,  ...,  0.2866, -0.0423,  0.0067]]]],\n","                           grad_fn=<CopyBackwards>)),\n","                   (tensor([[[[-0.2997,  1.0674, -0.2439,  ..., -0.2289, -0.6333, -0.6078],\n","                              [ 0.9438, -1.8757, -0.5755,  ...,  0.1229,  1.7929, -0.3130]],\n","                    \n","                             [[ 0.3514,  1.5137,  0.4524,  ...,  1.1948, -1.3977,  0.3308],\n","                              [ 0.1387, -1.1616, -0.6226,  ..., -2.1536, -0.1766, -1.1653]],\n","                    \n","                             [[-1.3330, -0.6003,  0.2709,  ...,  1.1001, -0.1418, -0.6230],\n","                              [-1.5638,  1.9531, -0.2184,  ..., -0.3042, -2.2814,  1.5291]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.4103, -0.2594, -0.7356,  ...,  0.4831,  0.0690,  0.3132],\n","                              [-0.5332,  0.1774,  1.8028,  ...,  0.1322,  0.1915, -0.9951]],\n","                    \n","                             [[-0.0831, -0.3862, -0.7452,  ..., -0.2725, -0.0534, -0.2660],\n","                              [-1.4382, -1.8134,  2.8000,  ..., -0.8421, -0.6358,  0.1198]],\n","                    \n","                             [[-1.0351, -0.4564, -1.0894,  ...,  0.2800, -0.1461, -0.3104],\n","                              [ 0.2128, -0.7712, -0.1874,  ..., -0.7119, -0.5132, -1.6355]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[-3.3177e-02, -1.8034e-04,  4.5827e-04,  ...,  1.3248e-02,\n","                                1.9023e-02,  3.2563e-02],\n","                              [-3.2167e-02, -1.5418e-01,  1.4814e-01,  ..., -2.6376e-01,\n","                                1.0807e-02, -6.4121e-01]],\n","                    \n","                             [[-1.0983e-02, -2.1240e-02, -4.1562e-02,  ..., -2.0584e-02,\n","                               -5.9072e-02, -6.3754e-02],\n","                              [-7.4979e-01,  4.7896e-01,  3.1803e-01,  ..., -2.9700e-01,\n","                               -1.4955e-01, -2.6639e-01]],\n","                    \n","                             [[ 5.7588e-02,  8.7107e-02, -3.4391e-02,  ..., -1.3255e-02,\n","                                2.8237e-02,  1.2374e-01],\n","                              [-6.9403e-01,  5.8305e-01, -4.0448e-03,  ...,  2.2897e-02,\n","                               -6.2816e-01,  3.7408e-01]],\n","                    \n","                             ...,\n","                    \n","                             [[-3.4895e-02,  7.3234e-03,  3.9967e-02,  ...,  4.8722e-02,\n","                               -6.5668e-02, -5.9926e-02],\n","                              [-1.0827e+00, -5.7699e-01,  4.4333e-01,  ...,  2.7596e-01,\n","                                9.1006e-01, -4.2224e-01]],\n","                    \n","                             [[-2.7116e-02,  1.4112e-02, -1.0806e-01,  ..., -2.1597e-02,\n","                                1.6286e-02,  6.7958e-03],\n","                              [ 2.9614e-01,  6.9683e-01,  2.1899e-01,  ...,  1.0725e-02,\n","                                3.8513e-02,  1.0382e-02]],\n","                    \n","                             [[ 5.4608e-03,  4.4768e-02, -1.2634e-02,  ...,  1.2816e-03,\n","                                3.0699e-02, -1.0643e-01],\n","                              [-3.3885e-01, -4.5145e-02,  4.8049e-02,  ..., -4.6988e-01,\n","                                2.6005e-01, -7.2162e-01]]]], grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 1.0374,  0.3910, -0.6754,  ...,  0.2131, -0.7792,  0.1073],\n","                              [ 0.6857,  0.6310, -0.8816,  ..., -0.0665,  0.0525, -0.0755]],\n","                    \n","                             [[ 0.5946, -0.2358, -1.0036,  ..., -0.7404, -1.1777, -2.7705],\n","                              [ 0.9685, -0.8442, -1.0034,  ..., -0.5313, -1.2558, -2.5045]],\n","                    \n","                             [[-0.8795, -0.7718, -1.1451,  ...,  0.3562,  0.6508, -0.3904],\n","                              [-0.6928, -1.3858, -1.1689,  ...,  0.9893,  0.1329, -0.7229]],\n","                    \n","                             ...,\n","                    \n","                             [[-2.6684, -0.8720,  0.7093,  ...,  1.3669,  1.9079,  0.6156],\n","                              [-3.0017, -0.5989,  0.8993,  ...,  1.0432,  1.9339, -0.0553]],\n","                    \n","                             [[-3.6058,  2.1486,  2.1966,  ...,  1.6174, -2.3318, -0.6465],\n","                              [-3.9024,  2.2764,  2.3965,  ...,  0.1705, -2.1405, -0.2133]],\n","                    \n","                             [[-0.7480,  1.9170,  1.3470,  ...,  0.4011, -0.4394, -1.1463],\n","                              [-0.3069,  1.8317,  1.8609,  ...,  0.0209, -0.2684, -0.9492]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.7396, -0.1129,  0.1192,  ..., -0.0200, -0.2694, -0.1733],\n","                              [ 0.9639, -0.3486, -0.0451,  ..., -0.7172, -0.3156,  0.1609]],\n","                    \n","                             [[ 0.0073, -0.7114, -0.4992,  ..., -0.3623, -0.2582,  0.3008],\n","                              [ 0.2753, -0.3529, -0.4996,  ..., -0.3469, -0.0021,  0.2831]],\n","                    \n","                             [[ 0.1104,  0.1524, -0.2274,  ..., -0.2116,  0.0372,  0.3177],\n","                              [ 0.2157,  0.3495, -0.1770,  ...,  0.2640, -0.0096,  0.4679]],\n","                    \n","                             ...,\n","                    \n","                             [[ 0.2203, -0.0463,  0.1329,  ...,  0.0979, -0.3664,  0.3431],\n","                              [-0.0973, -0.2557,  0.4457,  ...,  0.1551, -0.3278,  0.6508]],\n","                    \n","                             [[ 0.5532, -0.3937,  0.4316,  ..., -0.0912,  0.6116, -0.1449],\n","                              [ 0.6388, -0.4841,  0.4255,  ..., -0.0629,  0.5913, -0.1810]],\n","                    \n","                             [[ 0.4216, -0.3658, -0.3054,  ...,  0.1030,  0.0099, -0.1975],\n","                              [ 0.3812, -0.3219, -0.4682,  ..., -0.3154,  0.0673, -0.2982]]]],\n","                           grad_fn=<CopyBackwards>)),\n","                   (tensor([[[[-0.0638, -0.3080,  0.1955,  ..., -0.2980,  0.1688,  0.0431],\n","                              [ 0.5026, -0.5220,  3.4995,  ..., -1.0278,  0.1422,  2.3666]],\n","                    \n","                             [[ 0.4591,  0.1555, -0.1794,  ..., -0.2225, -0.4867,  0.2342],\n","                              [-0.4296, -0.2702, -0.8925,  ..., -1.1856,  0.8598, -0.2742]],\n","                    \n","                             [[-0.3287, -0.1999, -0.2862,  ..., -0.5182,  0.0972,  0.6838],\n","                              [ 2.6562,  1.6259, -1.6430,  ...,  0.5375,  1.0974, -3.0638]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.1022, -0.1004,  0.0337,  ..., -0.4126,  0.0917,  0.2785],\n","                              [-0.3013,  0.2233, -0.8632,  ..., -2.7654,  0.0675,  2.4467]],\n","                    \n","                             [[ 0.3300,  0.2506,  0.0510,  ..., -0.0276, -0.1510, -0.1070],\n","                              [-3.6227,  0.0169, -1.4157,  ..., -0.7226, -1.0749,  1.1248]],\n","                    \n","                             [[-0.0671, -0.4478, -0.0450,  ..., -0.1774, -0.1607, -0.0955],\n","                              [-4.6108,  0.6886,  0.8102,  ..., -0.4719,  0.8873, -2.4897]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[-0.0404, -0.0917,  0.0642,  ..., -0.0035, -0.0486,  0.0240],\n","                              [-0.2731,  0.0407,  0.5085,  ..., -0.1216, -0.2275, -0.7928]],\n","                    \n","                             [[ 0.0031, -0.1010,  0.0053,  ...,  0.0069, -0.0100,  0.0144],\n","                              [-0.1159, -0.6017,  0.1824,  ..., -0.1040,  0.0132,  0.0196]],\n","                    \n","                             [[ 0.1149, -0.0396, -0.0644,  ..., -0.1404,  0.0345,  0.0140],\n","                              [ 0.4707,  0.5479,  0.1769,  ..., -1.8493, -0.6008, -0.0666]],\n","                    \n","                             ...,\n","                    \n","                             [[ 0.0385, -0.0342, -0.0351,  ...,  0.0089, -0.0578,  0.0940],\n","                              [ 0.3749,  0.0586, -0.0326,  ..., -0.1291, -0.1929,  0.6304]],\n","                    \n","                             [[-0.0040,  0.0416,  0.0358,  ...,  0.0166,  0.0453,  0.0051],\n","                              [ 0.0923, -0.0818,  0.3751,  ...,  0.5956, -0.0576, -0.0671]],\n","                    \n","                             [[ 0.0988,  0.0028,  0.0458,  ...,  0.1539,  0.0561,  0.0554],\n","                              [ 0.0944, -0.1632,  0.0327,  ...,  0.9541,  0.3676,  0.2072]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.4540, -0.9974, -2.6459,  ...,  1.1923, -0.3397,  3.7741],\n","                              [ 0.5595, -0.9436, -1.4177,  ...,  0.9573, -0.9510,  3.5285]],\n","                    \n","                             [[ 0.5767, -1.4281, -0.0372,  ...,  0.2962,  1.1243,  1.1418],\n","                              [-0.3780, -1.4567,  1.4320,  ..., -0.2319,  0.4736,  0.6123]],\n","                    \n","                             [[ 0.4139, -1.4614, -0.8103,  ..., -3.3714,  0.1478,  0.2090],\n","                              [-0.1716, -1.2067, -0.2029,  ..., -2.4051, -0.5142,  0.5125]],\n","                    \n","                             ...,\n","                    \n","                             [[-3.4578, -0.9712,  0.9847,  ..., -0.2011, -1.6939,  0.2227],\n","                              [-1.9282, -0.9421,  0.6625,  ..., -0.3203, -2.4944,  0.4157]],\n","                    \n","                             [[-1.9077,  2.6054,  0.7046,  ...,  3.3153,  0.8114, -1.1166],\n","                              [-0.5560,  2.4935,  1.0945,  ...,  3.5782,  0.8835, -1.7877]],\n","                    \n","                             [[-0.7894, -0.6044, -0.4530,  ...,  2.1209, -1.0290,  1.3274],\n","                              [-1.5356,  0.6271, -1.3167,  ...,  1.9269, -1.3602,  2.0155]]]],\n","                           grad_fn=<CopyBackwards>),\n","                    tensor([[[[ 0.2468,  0.4531, -0.2456,  ..., -0.2639, -0.4747,  0.2349],\n","                              [ 0.6563,  0.5046, -0.2421,  ...,  0.0345, -0.6680,  0.2661]],\n","                    \n","                             [[ 0.1554,  0.0104,  0.0888,  ...,  0.5652,  0.1155,  0.2966],\n","                              [ 0.2705, -0.4564,  0.2788,  ...,  0.3807,  0.1667,  0.0607]],\n","                    \n","                             [[-0.5218, -0.1890,  0.0533,  ..., -0.1139,  0.2080, -0.0636],\n","                              [-0.3670, -0.1278, -0.1607,  ...,  0.1446, -0.0988, -0.1946]],\n","                    \n","                             ...,\n","                    \n","                             [[-0.0757,  0.8512,  0.1290,  ...,  0.5617,  0.4623, -0.4476],\n","                              [-0.1185,  0.9600,  0.4644,  ...,  0.6976,  0.4706,  0.1709]],\n","                    \n","                             [[ 0.0076, -0.1633,  0.0613,  ..., -0.4322, -0.1017,  0.0051],\n","                              [ 0.0926, -0.3790,  0.3583,  ..., -0.1947, -0.1139, -0.2700]],\n","                    \n","                             [[ 0.8125,  0.0627,  0.4241,  ...,  0.3436,  0.0131, -0.7254],\n","                              [ 0.4459,  0.2707,  0.4448,  ...,  0.2226,  0.4030, -0.7320]]]],\n","                           grad_fn=<CopyBackwards>)))),\n","                 ('encoder_last_hidden_state',\n","                  tensor([[[ 0.4624, -0.2475,  0.0902,  ...,  0.1127,  0.6529,  0.2203],\n","                           [ 0.4538, -0.2948,  0.2556,  ..., -0.0442,  0.6858,  0.4372]]],\n","                         grad_fn=<NativeLayerNormBackward>))])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"zdfWFv-TZbyT","executionInfo":{"status":"ok","timestamp":1633256778612,"user_tz":-540,"elapsed":4036,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["import pandas as pd\n","train = pd.DataFrame(columns=['uid', 'title', 'region', 'context', 'summary'])\n","uid = 1000\n","for data in TRAIN_DATA:\n","    for agenda in data['context'].keys():\n","        context = ''\n","        for line in data['context'][agenda]:\n","            context += data['context'][agenda][line]\n","            context += ' '\n","        train.loc[uid, 'uid'] = uid\n","        train.loc[uid, 'title'] = data['title']\n","        train.loc[uid, 'region'] = data['region']\n","        train.loc[uid, 'context'] = context[:-1]\n","        train.loc[uid, 'summary'] = data['label'][agenda]['summary']\n","        uid += 1\n","\n","test = pd.DataFrame(columns=['uid', 'title', 'region', 'context'])\n","uid = 2000\n","for data in TEST_DATA:\n","    for agenda in data['context'].keys():\n","        context = ''\n","        for line in data['context'][agenda]:\n","            context += data['context'][agenda][line]\n","            context += ' '\n","        test.loc[uid, 'uid'] = uid\n","        test.loc[uid, 'title'] = data['title']\n","        test.loc[uid, 'region'] = data['region']\n","        test.loc[uid, 'context'] = context[:-1]\n","        uid += 1"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"3CwvYKTRZbyW","executionInfo":{"status":"ok","timestamp":1633256782378,"user_tz":-540,"elapsed":794,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["train['total'] = train.title + ' ' + train.region + ' ' + train.context\n","test['total'] = test.title + ' ' + test.region + ' ' + test.context\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"JpWK8OLRZbyY","executionInfo":{"status":"ok","timestamp":1633256784176,"user_tz":-540,"elapsed":3,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["df_train = train.iloc[:-200]\n","df_val = train.iloc[-200:]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"YpaXNPCGZbyb","executionInfo":{"status":"ok","timestamp":1633258283596,"user_tz":-540,"elapsed":793,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["import os\n","import glob\n","import torch\n","import ast\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm, trange\n","from torch.utils.data import Dataset, DataLoader, IterableDataset\n","\n","class KoBARTSummaryDataset(Dataset):\n","    def __init__(self, file, tok, max_len=512, pad_index = 0, ignore_index=-100, train=True):\n","        super().__init__()\n","        self.tok = tok\n","        self.max_len = max_len\n","        self.docs = file\n","        self.len = len(self.docs)\n","        self.pad_index = pad_index\n","        self.ignore_index = ignore_index\n","        self.train = train\n","\n","    def add_padding_data(self, inputs):\n","        if len(inputs) < self.max_len:\n","            pad = np.array([self.pad_index] *(self.max_len - len(inputs)))\n","            inputs = np.concatenate([inputs, pad])\n","        else:\n","            i=0\n","            l=np.zeros(((len(inputs)//self.max_len),self.max_len))\n","            while ((len(inputs)//self.max_len)-i)>0:           \n","                  l[i] = inputs[i*(self.max_len):(i+1)*(self.max_len)]\n","                  i+=1\n","            inputs=l\n","        return inputs\n","\n","    def add_ignored_data(self, inputs):\n","        if len(inputs) < self.max_len:\n","            pad = np.array([self.ignore_index] *(self.max_len - len(inputs)))\n","            inputs = np.concatenate([inputs, pad])\n","        else:\n","            inputs = inputs[:self.max_len]\n","        return inputs\n","    \n","    def __getitem__(self, idx):\n","        instance = self.docs.iloc[idx]\n","        context = instance['context']\n","        if self.train:\n","            summary = instance['summary']\n","        input_ids = self.tok.encode(context)\n","        input_ids = self.add_padding_data(input_ids)\n","\n","        if self.train:\n","            label_ids = self.tok.encode(instance['summary'])\n","            label_ids.append(self.tok.eos_token_id)\n","            dec_input_ids = [self.pad_index]\n","            dec_input_ids += label_ids[:-1]\n","            dec_input_ids = self.add_padding_data(dec_input_ids)\n","            label_ids = self.add_ignored_data(label_ids)\n","\n","\n","            return {'input_ids': np.array(input_ids, dtype=np.int_),\n","                    'decoder_input_ids': np.array(dec_input_ids, dtype=np.int_),\n","                    'labels': np.array(label_ids, dtype=np.int_)}\n","        else:\n","            return {'input_ids': np.array(input_ids, dtype=np.int_),}\n","    \n","    def __len__(self):\n","        return self.len"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"MraUgBqFZbyg","executionInfo":{"status":"ok","timestamp":1633258287269,"user_tz":-540,"elapsed":5,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["test_dataset = KoBARTSummaryDataset(file=df_val, tok=kobart_tokenizer, train=False)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, num_workers=args.num_workers, shuffle=False)"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLnHYX5Gxic3","executionInfo":{"status":"ok","timestamp":1633258214263,"user_tz":-540,"elapsed":426,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"ecf989c1-4953-4b57-e45b-51188455668e"},"source":["test_dataset[-1]"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["[29072. 17208. 23361. 14789. 11900. 11280. 16669. 29072. 17208.  9120.\n"," 14081.  9123. 23381.  9866. 14459. 12141. 12258. 11900. 22316. 18664.\n"," 14581. 17770. 29883. 18115. 14979. 20473. 16499. 12005. 14092. 21102.\n"," 14640. 12013. 14633. 15449. 13672. 13724.   243. 14459. 12141. 14979.\n"," 22316. 14573. 24991. 14581. 17770. 29883. 14338.  1834. 14745.   249.\n"," 14515.  9866. 14979. 22316. 14573.  1835. 14062. 10339. 11786. 14131.\n"," 12013.   240. 21916. 29072. 17208.  9120. 14081.  9123. 23381.  9866.\n"," 14979. 22316. 14573. 29244. 16571. 29883. 29244. 14172. 12002. 17512.\n"," 25925. 26638. 14410.  9743. 14158. 23770. 25925. 14330. 21888.  9264.\n"," 25490. 14562. 17236. 13699. 14410.  9743. 25925. 14330. 21888.  9264.\n"," 25490. 14562. 23433.  9743. 14490. 18940.  9694. 14218. 14032.  9102.\n"," 20032. 15170. 14850. 12819. 13468. 12344. 12612. 18448. 29072. 17208.\n","  9120. 14058. 23807. 14080.  9495. 17784. 14104.   243. 18068. 14058.\n"," 23807. 17596. 14880.  9120. 14030. 15090. 14058. 14026. 17327. 16574.\n"," 22879. 11973. 11239.  9120. 14058.   245. 14850. 12819.  8981. 27256.\n"," 14651. 14794. 14256.  9869.  9618. 12074. 14440. 25899. 14850. 12819.\n"," 13468. 12344. 12612. 15979. 21366. 28642. 14080.  9495. 17784. 26393.\n"," 14177. 14681.  9698. 14231. 14788. 14082. 14256.  9869.  9618. 17458.\n"," 14880.  9120. 14030. 17217. 14668. 14219. 12344. 13590. 14173. 15331.\n"," 20628. 14231. 14788. 18585. 15848. 17217. 13594. 14032. 15313. 14440.\n"," 15734. 12244.   262. 21804. 14491. 17214. 18068. 14190. 14275. 14334.\n"," 18187. 15170. 14104.   243. 14880.  9120. 14030. 16981. 14476. 22611.\n"," 14256.  9869.  9618. 23105. 14669. 14343. 14850. 12819. 10338. 16658.\n"," 14231. 14788. 27361. 14449. 14262. 15159. 15094. 17196. 27980. 17537.\n"," 14456. 14032. 15489.  9475. 14097. 27721. 14303. 14440. 14374. 29072.\n"," 17208.  9120. 14590. 14605. 17219. 18455. 14082. 14118. 12244.   262.\n"," 14104.   243. 14764. 15170. 14376. 18343. 15709. 27980. 17537. 14456.\n"," 14032. 15489. 17939. 14088. 21888.  9269. 15890. 26652. 14093. 10184.\n"," 13590. 11911. 14573. 14394. 14366. 15331. 27449. 12244.   262. 14214.\n"," 11911. 10184. 14573. 15331. 20628. 14214. 11911. 10184. 14573.   245.\n"," 14028. 21053. 15638. 15279. 18093. 12034. 15860. 14105. 15118. 15332.\n"," 20467. 20039. 13607. 22975.  9810. 14173. 15806. 16144. 14475. 20552.\n"," 14792. 22678. 16390. 15399. 14991. 14303. 14440. 14262. 21467. 10213.\n"," 14336. 14449. 12332. 14440. 14906.  9866. 15987. 23008. 14088. 21888.\n","  9264. 25490. 14562. 14446. 14214. 11911. 10184. 24957. 14596. 13676.\n"," 14030. 14434. 12007. 14432. 20628. 26393. 14596. 13676. 20988. 15709.\n"," 14432. 15332. 14379. 17251. 26755.  9264. 14908. 12074. 16613. 21804.\n"," 14033. 14813. 14490. 13607. 21888.  9264. 25490. 14562. 29072. 17208.\n","  9120. 14497. 12786. 11211. 17208. 25344. 26755.  9264. 16669. 14110.\n","  9241. 14410. 26582. 15914. 19886. 14214. 11911. 10184. 24957. 17932.\n"," 26393. 14459. 18143.   243. 14596. 13676. 18143. 15709. 14281. 14136.\n","   243.   255. 16266. 15399. 22512. 24500. 25346. 14081. 14121. 12786.\n"," 17167. 17027. 14196.  9770. 14182. 14463. 11683. 19502. 26350. 20285.\n"," 20628. 14955. 14475. 23559. 16341. 26393. 14634. 11471. 15700. 14432.\n"," 15332. 23218. 14424. 19254. 15655. 15844. 17642. 14812. 23218. 14424.\n"," 14469. 10338.  9495. 14362. 20552. 14141. 14058. 18287. 24874. 14105.\n"," 15118. 11264. 15023. 17382. 15399. 11786. 15638. 14081. 12335. 13594.\n"," 14032. 14821. 17489. 16467. 14634. 15542. 16767. 15170. 14380. 21993.\n"," 16810. 14036. 24043. 15543. 20878. 18196. 14191. 16119. 14214. 11911.\n"," 10184. 18664. 14236. 14173. 15331. 15332. 14036. 16316. 14455. 15097.\n"," 12244.   262. 14104.   243. 14028. 14455. 15097. 15170. 15037. 16265.\n"," 14036. 21813.]\n","[14074. 16469. 14581. 13590. 14262. 14426. 14033. 17054. 14543. 14955.\n"," 14549. 14734. 14340. 27269. 14025. 19050. 20706. 15693. 15118. 11264.\n"," 14199. 21993.  9173. 28640.  9866. 22804. 15543. 15693. 14466. 14032.\n"," 15489.  9475. 14605. 17939. 14088. 21888.  9264. 25490. 14562. 14487.\n"," 14285. 17149. 14246. 21763. 18193. 14303. 14214. 11911. 10184. 13590.\n"," 11911. 14025. 12471.  9866. 14972. 14056. 19867. 14303. 14596. 13676.\n"," 25899. 22245. 12007. 15709. 16467. 14088. 14543. 22456. 21702. 18656.\n"," 15176. 14938. 16334. 14605. 14669. 14528. 15332. 14199. 29072. 17208.\n","  9120. 14030. 14605. 23928. 29334. 14034. 14704. 14088. 21888.  9264.\n"," 25490. 14562. 14334. 14177. 29883. 14333. 16669. 14153. 25925. 26638.\n"," 14410.  9743. 14158. 11478. 27879. 14092. 13744. 11265. 14410.  9743.\n"," 25925. 13607. 21888.  9264. 25490. 14562. 23433.  9743. 16345. 23111.\n"," 14490. 18940. 15217.  9102. 14032.  9102. 13586. 11478. 14562. 14308.\n"," 12471. 28530. 25925. 17770. 29883. 15484. 11028. 10948. 11373.  9866.\n"," 17535. 17130. 13714. 14423. 14573. 14334. 14432. 27449. 14304. 14042.\n"," 17691. 14972. 14062. 11373.  9866. 18547. 14634. 24301. 15709. 14182.\n","   252. 13699. 14747. 21045. 14117. 18764. 26908. 20604. 16158. 23855.\n"," 24789. 15078. 18058. 13590. 16605. 21464. 17784. 14974. 17214. 18691.\n"," 15220. 15459. 15129. 15364.  9698. 27915. 15679. 14502. 14062. 11373.\n","  9866.  9039. 14527. 18102. 15131. 20470. 17535.  9264. 17035. 20628.\n"," 15037. 26393. 16869. 17535. 13590. 14494. 14308. 23286. 14333. 14350.\n"," 17242. 15743. 20628. 14475. 15109. 21122. 18778. 16593. 17427. 14026.\n"," 27927. 15472. 15694. 11264. 14236. 14262. 18691. 14285. 16707. 15292.\n"," 18799. 14290. 14643. 10370. 10443. 16546. 14308. 23286. 14333. 18778.\n"," 16593. 17427. 20628. 20757.  9039. 15798. 15321. 14118. 12244.   262.\n"," 14285. 16707. 15292. 18799. 18102. 15131. 20470. 20418. 10443. 14236.\n"," 27944. 14285. 16707. 16960. 28559. 13607.  9001.  9102. 18799. 14723.\n"," 14042. 11467. 14090. 15914. 12034. 11465. 12244.   262. 14858. 14955.\n"," 17032. 22611. 14220.  9584. 14150. 17130. 19410. 14027. 15097. 18900.\n"," 14158.  9866. 28842. 17050. 14158. 14704. 14334. 13586. 22344. 19682.\n"," 24789. 10386. 10213. 24681. 14593. 14135. 25894. 17517. 18194.  9475.\n"," 15109. 17939. 14088. 16518.  9102. 14543. 14787. 12471. 28530. 17820.\n"," 16611. 14573. 14779. 15709. 14584.  9102. 22299. 14059. 15933. 18664.\n"," 14036. 15634.  9925. 14455. 17887. 18764. 14443.   236. 14455. 14036.\n"," 14033. 22802. 14584.  9102. 11747. 15028. 17508. 22486. 14076.  9495.\n"," 17784. 14446. 18251. 14605. 20628. 15037. 26393. 17808. 14087. 10488.\n"," 15208. 15920. 12034. 14105. 15743. 20628. 15634. 23735. 14475. 14082.\n"," 21240. 16719. 17997. 14032. 22802.  9866. 16759. 14446. 15344. 16343.\n"," 17195. 14972. 17508. 14209. 24695. 14033. 14163. 15170. 14747. 14209.\n"," 24695. 14261. 17685. 18525. 21464. 17784. 14446. 18068. 16427. 16118.\n"," 26025. 14033. 23014. 14432. 15332. 14584.  9102. 11747. 15188. 14794.\n"," 14719. 14082. 24955. 10500. 23886. 14432. 29565. 16118.  8981. 14105.\n"," 15743. 16269. 14379. 17569. 14209. 17033. 14562. 26393. 22255. 14593.\n"," 25898. 11028.  9495. 14032.  9770. 14293. 14374. 18869. 14672. 16118.\n"," 26025. 14033. 22519. 17442. 16467. 14432. 14609. 15914. 12034. 11467.\n","  8981. 17784. 17820. 16892. 14058. 25810. 15709. 14028. 17972. 22245.\n"," 14668. 14432. 20628. 14177. 29883. 16371.  8985. 17032. 18068. 15386.\n"," 10500. 15766. 14446. 14087. 10488. 15026. 17508. 14467. 14033. 22802.\n"," 14440. 20662. 15055. 13619. 14477. 14365. 14368. 14466. 14033. 22802.\n"," 14246. 14310. 21914. 17508. 19015. 11264. 15987. 25925.  9989. 10325.\n"," 15170. 14166. 17939. 14432. 15911. 14668. 14028. 20552. 14634. 12034.\n"," 14466. 14032.]\n","[14821. 16767. 15170. 14487. 14252. 12471. 18043. 14524. 12926. 27364.\n"," 27518. 29532. 20853. 14304. 21066. 14497. 19058. 14279. 15987. 14549.\n"," 14734. 14432. 14548. 19737. 17538. 20113. 14881. 14033. 29960. 14549.\n"," 14734. 14105. 14340. 10325. 14304. 14475. 14068. 12797. 25124.  8981.\n","  9115. 26183. 14459. 14030. 15090. 11973. 13124. 12007. 25351. 11264.\n"," 21993. 12681.  9074.  9102. 12797.  8981. 21689. 14871. 12007. 14432.\n"," 15332. 14524. 12926. 27364. 10518. 12074. 14096. 24681. 14445. 19867.\n"," 12007. 15705. 14236. 14087. 26029. 21993.  9102. 12797.  8981. 21689.\n"," 25239. 14432. 21464. 17784. 14068. 12797. 25124.  9866. 25239. 14432.\n"," 20628. 14285. 17149. 21507. 16942. 12007. 14089. 21993. 12681.  9074.\n","  9102. 12797.  8981. 21689. 25239. 14105. 14236. 14174. 14416. 14166.\n"," 14178. 16636. 14033. 14163. 15170. 14487. 14445. 14355. 14331. 14186.\n"," 14166. 14605. 14132. 28486. 15380. 22717. 14376. 19474. 14792. 15098.\n"," 13594. 14032. 14082. 20246. 14080.  9495. 17784. 26393. 14446. 25346.\n"," 14871. 14497. 11211. 15049. 23014. 14432. 15332. 18068. 14524. 12926.\n"," 27364. 10518. 14266. 25346. 24706. 10500. 14301. 19174. 20628. 14524.\n"," 12926. 27364. 10518. 12074. 18841. 19867. 12005. 14380. 25346. 24706.\n"," 23014. 14365. 19396. 14236. 26185. 28037. 14157. 16416. 16546. 20810.\n"," 14355. 14261. 20067. 21978. 14068. 12797. 25124.  8981.  9115. 15156.\n"," 12005. 14459. 14030. 17364. 15709. 15090. 11973. 13124. 10500. 14236.\n"," 26448. 27594. 21993.  9173. 14068. 12797.  8981. 21689. 25239. 14236.\n"," 28020. 14955. 14440. 20662. 19867. 14058. 23541. 15709. 14132. 28486.\n"," 15118. 11264. 25239. 14207. 14032. 15489.  9475. 17489. 19024. 11306.\n"," 14553. 14236. 17983. 12007. 14340. 10487. 14562. 14104.   243. 14177.\n"," 29883. 14437.   243. 15524.  9499. 13607. 11786. 21529. 21942. 14340.\n"," 28958. 16345. 14129. 28362. 14315. 19737. 29274. 26753. 15709. 14285.\n"," 17149. 15987. 27518. 14327. 11715. 14304. 29274. 14105. 14464. 14033.\n"," 14163. 15170. 22956. 16942. 12007. 14089. 14028. 24525. 15099. 28992.\n"," 18187. 14101. 16371.  8985. 14376. 14906. 15421. 14166. 23928. 16699.\n"," 12258. 11306. 14553. 14236. 17983. 12007. 14340. 14268. 14543. 27694.\n"," 19565. 23851. 14779. 10213. 24681. 14757. 23851. 15617. 13714. 14423.\n"," 14379. 14030. 14437. 14524. 12926. 27364. 26299. 20964. 23990. 23891.\n"," 16373. 14056. 14408. 13737. 14668. 21045. 12244.   262. 14858. 14497.\n"," 15305. 14605. 22474. 14315.  9495. 17784. 14446. 14475. 23485.  9618.\n","  8981. 14455. 14632. 28465. 23485.  9618. 15305. 26522. 22474. 14105.\n"," 16681. 14497. 15305. 22474. 14036. 17556. 17784. 15153. 15769. 12034.\n"," 14464. 27944. 18572. 14757.  9242. 17087. 22474. 16681. 14497. 14542.\n"," 14036. 15417.   325. 17500.  9618.  8981.  9866. 14105. 15097.  9810.\n"," 26185. 14285. 17149. 15920. 12007. 14315. 19737.   245. 17444. 14355.\n"," 19867. 14058. 14091. 17035. 15743. 23656. 23779. 11264. 23485.  9618.\n","  8981. 21143. 16981. 14476. 23485. 11802. 14497. 15305. 15097. 14304.\n"," 26554. 14972. 18043. 14497. 11211. 15689. 14777.  9908. 14262. 14437.\n"," 14058. 14446. 14058. 14035. 16562.   256.   236. 11828. 14543. 23515.\n"," 14455. 14823. 14777.  8981. 14105. 15097. 15170. 14437. 15623. 14652.\n"," 14524. 12926. 27364. 15911. 14058. 14632.  9618.  8981. 26795. 18764.\n"," 27594. 16092. 14275. 18603. 14262. 15622. 14426. 14033. 14163. 15170.\n"," 14593. 17685. 18525. 21464. 17784. 14446. 14757.  9242. 15647. 14105.\n"," 15743. 22456. 21702. 16093. 21484. 17569. 17285. 14404. 14677. 15170.\n"," 26393. 14469. 10338.  9495. 14362. 14757.  9242. 15647. 14105. 14151.\n","  9754. 21702. 24239. 17569. 18237. 24135. 14362. 21993. 11211. 24706.\n"," 14303. 18043.  9618. 11211. 15689. 15003. 14481. 14404. 14677. 15170.\n"," 28281. 14450.]\n","[14033. 14058. 21353. 15171. 21484. 14058.  9698. 14417. 17828. 16111.\n"," 14033. 22802.   262. 14446. 14516. 15390. 13590. 14262. 21993. 11211.\n"," 14497. 11211. 15689. 25759.   250. 16266. 14455. 17621. 16417. 14147.\n"," 21571. 15114. 14747. 28914. 14362. 28281. 14145. 12687. 14184. 14996.\n"," 21914. 15189.  8989. 15764. 15099. 15170. 15100. 14157. 14634. 25494.\n"," 25461. 18251. 18274. 15189.  8989. 22728. 14246. 20357. 21993. 11211.\n"," 24706.  9866. 19177. 14036. 14043. 15899. 17245. 18996. 14455. 14258.\n"," 17926. 15097. 14304. 24706. 17536. 20004. 13514. 12037. 14269. 21993.\n"," 25859. 20553. 14049. 21914. 14945. 14455. 14151. 12244.   262. 14446.\n"," 26393. 14036. 20462. 14455. 14581. 20628. 14423. 20257. 14147. 14331.\n"," 11224. 23105. 17187.  9475.   243. 16227. 15286. 15321. 22953. 15109.\n"," 15286. 20265. 14236. 14376. 23299. 12034. 20628. 17490. 14440. 14906.\n","  9866. 24706. 18841. 20004. 13514.  9866. 19177. 27829. 14276. 19146.\n"," 14466. 14033. 14163. 15170. 17489. 17939. 15709. 14199. 21993. 16921.\n","  9120. 14497. 11211. 15689. 14605. 15390. 12034. 14466. 14032. 14821.\n"," 15278. 14642. 15170. 14487. 14153. 14035. 14891. 14437. 14757. 23851.\n"," 21845.  9758.  8981. 18486. 14636. 16960. 19053. 12007. 14315. 14553.\n"," 14271. 16330. 18764. 20317. 19932. 19053. 12034. 15097.  9495. 17784.\n"," 14974. 19053. 12034. 14105. 15097. 15170. 29744. 26393. 20317. 22972.\n"," 14198. 15949. 20553. 14058. 14215.  9698. 14262. 16269. 14974. 14200.\n"," 14432. 20628. 14757. 23851. 15215. 18486. 14636. 14058. 15390.  9758.\n","  8981. 18486. 14636. 14058. 25023. 17031. 16482. 29147. 14423.  9758.\n","  8981. 18486. 22972. 15595. 14871. 14631. 21010. 14168. 14303. 14871.\n"," 15335. 18793. 19127. 12159. 16252. 19918. 14033. 14163. 15170. 14955.\n"," 14028. 14906. 15421. 22398. 11264. 19024. 11306. 14553. 14236. 15394.\n"," 14502.   245. 14153. 14035. 14891.   243. 24706.  9421. 10277. 10746.\n"," 15390. 18664. 14315. 11779. 29147. 15037. 17290. 11786. 14124. 21300.\n"," 15867. 18323.  9925.  9264. 14043.  9758. 17035. 14086. 17172. 10338.\n"," 15372. 15142. 21729. 14506. 17595. 14025. 23189. 14755. 14985. 12034.\n"," 14466. 14269. 24706.  9421. 10277. 10746. 18664. 14153. 14461. 15286.\n"," 14829. 16888. 28226. 20364. 17784. 14757. 23851. 15215. 18486. 20172.\n"," 15939. 11264. 21152. 16416. 14432. 20628. 14376. 19474. 14145. 10500.\n"," 13842. 14315. 14553. 14236. 17983. 12007. 14340. 14268. 14543. 14376.\n"," 16467. 14207. 14269. 14060. 10047. 15390. 12034. 14105. 15743. 14106.\n"," 15689.  9754. 21702. 15183.  8981. 15787. 14843. 29365. 14506. 18710.\n"," 19276. 12034. 14151. 14506. 14440. 19050. 16234. 14033. 14163. 15170.\n"," 14955. 21275. 17365. 20227. 15709. 14184. 14424. 17032. 29022. 12034.\n"," 23864. 15183.  8981. 15787. 15438. 21609. 14090. 16393. 14172. 14033.\n"," 14163. 15170. 16900. 21492. 12007. 20252. 25984. 16767. 15170. 16371.\n","  8985. 14032. 13607. 14058. 14166.  9173.  9754.  9495. 14469. 10338.\n","  9495. 10338. 18593. 17508. 14605. 19733. 27449. 14304. 14345. 14391.\n"," 14440. 14906. 14282. 17050. 15593. 14668. 19437. 24761. 21888. 14241.\n"," 17983. 17770. 14125. 16571. 29883. 21609. 15170. 21609. 15170. 14153.\n"," 25925. 26638. 14410.  9743. 14158. 11478. 27879. 25925. 26638. 14410.\n"," 16613. 14105. 27449. 15273. 25925.  1286.  9767. 25419. 16571. 29883.\n"," 29072. 17208. 23361.  9743. 14032.  9102. 20032. 15170. 21916. 20538.\n"," 14491.  9908. 16588. 12041. 14477. 14422. 16571. 14795. 15639. 16833.\n"," 14288. 16910. 14862. 18531. 17370. 12612. 24124. 14275. 21875.  9605.\n"," 12332.  9120. 14226. 19444. 14062. 17660. 14979. 22316. 14573. 29244.\n"," 15428. 29883. 14355. 20139. 14080. 12002. 23770. 17370. 20570. 13737.\n"," 21993. 16810. 13737. 17711. 13737. 26139. 14285. 18809. 14422. 19686.\n"," 12060. 25742.]\n"]},{"output_type":"execute_result","data":{"text/plain":["{'input_ids': array([[    0,     0,     0, ...,     0,     0,     0],\n","        [    0,     0,     0, ...,     0,     0,     0],\n","        [    0,     0,     0, ...,     0,     0,     0],\n","        [14033, 14058, 21353, ..., 19686, 12060, 25742]])}"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"mMiG2yxvZbyg","executionInfo":{"status":"ok","timestamp":1633256796535,"user_tz":-540,"elapsed":406,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["import torch\n","import torch.nn as nn\n","class KobartSummaryModule(nn.Module):\n","    def __init__(self, device):\n","        super().__init__()\n","        self.device = device\n","        self.model = BartForConditionalGeneration.from_pretrained(get_pytorch_kobart_model()).to(self.device)\n","        \n","    def forward(self, input, train=True):\n","        input_ids = torch.as_tensor(input[\"input_ids\"]).to(self.device)\n","        if train:\n","            decoder_input_ids = torch.as_tensor(input[\"decoder_input_ids\"]).to(self.device)\n","            labels = torch.as_tensor(input[\"labels\"]).to(self.device)\n","\n","            if len(input_ids.shape) == 1:\n","                input_ids, decoder_input_ids, labels = input_ids.unsqueeze(0), decoder_input_ids.unsqueeze(0), labels.unsqueeze(0)\n","            \n","            return_dict = self.model(input_ids=input_ids, decoder_input_ids=decoder_input_ids, labels=labels) \n","\n","            loss = return_dict[\"loss\"]\n","\n","            return loss, return_dict\n","        else:\n","            if len(input_ids.shape) == 1:\n","                input_ids = input_ids.unsqueeze(0)\n","                \n","            return_dict = self.model(input_ids=input_ids)\n","\n","            return return_dict\n","\n","    def generate(self, input, num_beams=4, max_length=50, early_stopping=True):\n","        input_ids = torch.as_tensor(input[\"input_ids\"]).to(self.device)\n","        if len(input_ids.shape) == 1:\n","                input_ids = input_ids.unsqueeze(0)\n","\n","        return self.model.generate(input_ids, num_beams=num_beams, max_length=max_length, early_stopping=early_stopping)\n","\n","        \n","\n","        \n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiEFszkgZbyj","executionInfo":{"status":"ok","timestamp":1633256815715,"user_tz":-540,"elapsed":16168,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"f28e2a20-00b5-4cf6-8d75-6bb20afd0be6"},"source":["device = \"cuda\"\n","model = KobartSummaryModule(device=device)\n","model.load_state_dict(torch.load(args.save_path + \"/model_1.pth\"))\n","#return_dict = model(input, train=False)\n","#logits = return_dict[\"logits\"]"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["using cached model\n"]},{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ogOdBt3erAtc","executionInfo":{"status":"ok","timestamp":1633256519969,"user_tz":-540,"elapsed":452,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"dd3ee1fe-ad92-428c-8cdd-fc30773c7d7c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"2aO7PsH1Zbyk"},"source":["#summary_ids = model.generate(input, num_beams=4, max_length=100, early_stopping=True)\n","#print([kobart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0U07yfZcZbym","executionInfo":{"status":"ok","timestamp":1633256822889,"user_tz":-540,"elapsed":816,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["def decode_summary(summary_ids):\n","    return [kobart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBJOR7ZfZbym","executionInfo":{"status":"ok","timestamp":1633257227758,"user_tz":-540,"elapsed":835,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}}},"source":["def summarization(i):\n","    context = df_val.iloc[i][\"context\"]\n","    input = test_dataset[i]\n","    summary_ids = model.generate(input, num_beams=4, max_length=100, early_stopping=True)\n","    summary = decode_summary(summary_ids)\n","\n","    return{\"context\": context, \"summary\": summary}"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wtnOxKQaV0b"},"source":["stride=20\n","length=500\n","for i in range(test.shape[0])\n","   if len(test.iloc[i][\"context\"])>700\n","      for j in range((test.iloc[i][\"context\"]-length)//stride))\n","         context = test.iloc[i][\"context\"][(j*stride):(j*stride)+length]\n","         input="],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acCoErEscqdx","executionInfo":{"status":"ok","timestamp":1633254080860,"user_tz":-540,"elapsed":382,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"c193771e-f352-430e-b4ff-90b31d1c4ec2"},"source":["stride=20\n","length=500\n","j=0\n","print(test.iloc[0][\"context\"][(j*stride):(j*stride)+length])\n","print(len(test.iloc[0][\"context\"]))\n","print(len(test_dataset[0]['input_ids']))\n"],"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["ÏùòÏÑùÏùÑ Ï†ïÎèàÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÏÑ±ÏõêÏù¥ ÎêòÏóàÏúºÎØÄÎ°ú ÏßÄÍ∏àÎ∂ÄÌÑ∞ ÏùåÏÑ±Íµ∞ÏùòÌöå Ï†ú235Ìöå Ï†ú1Ï∞® Ï†ïÎ°ÄÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùòÎ•º Í∞úÏùòÌïòÍ≤†ÏäµÎãàÎã§. Î®ºÏ†Ä ÏùòÌöåÏÇ¨Î¨¥Í≥ºÏû•ÏúºÎ°úÎ∂ÄÌÑ∞ Î≥¥Í≥†Í∞Ä ÏûàÍ≤†ÏäµÎãàÎã§. ÏùòÌöåÏÇ¨Î¨¥Í≥ºÏû•ÏûÖÎãàÎã§. Î®ºÏ†Ä ÏßÄÎÇú Ï†ú234Ìöå ÏûÑÏãúÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùòÏóêÏÑú ÏùòÍ≤∞ÌïòÏó¨ Ïù¥ÏÜ°Ìïú ÏïàÍ±¥Ïóê ÎåÄÌï¥ÏÑú Î≥¥Í≥†Î•º ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. 2012ÎÖÑ 5Ïõî 29Ïùº Ï†ú1Ï∞® Î≥∏ÌöåÏùòÏóêÏÑú ÏùòÍ≤∞ÌïòÏó¨ Ïù¥ÏÜ°Ìïú ÏùåÏÑ±Íµ∞ ÏßÄÎ∞©Í≥µÎ¨¥Ïõê Ï†ïÏõê Ï°∞Î°Ä ÏùºÎ∂ÄÍ∞úÏ†ïÏ°∞Î°ÄÏïàÏùÄ 2012ÎÖÑ 6Ïõî 15ÏùºÏûêÎ°ú Í≥µÌè¨ÎêòÏóàÏäµÎãàÎã§. Îã§ÏùåÏùÄ Ï†ú235Ìöå Ï†ú1Ï∞® Ï†ïÎ°ÄÌöå Ï†ú1Ï∞® Î≥∏ÌöåÏùòÏôÄ Í¥ÄÎ†®ÌïòÏó¨ Î≥¥Í≥† ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. „ÄåÏßÄÎ∞©ÏûêÏπòÎ≤ï„ÄçÏ†ú44Ï°∞ Î∞è „ÄåÏùåÏÑ±Íµ∞ ÌöåÍ∏∞ÏôÄ Í∑∏ Ïö¥ÏòÅ Îì±Ïóê Í¥ÄÌïú Ï°∞Î°Ä„ÄçÏ†ú4Ï°∞Ï†ú1Ìï≠Ïóê Îî∞Îùº Ï†ïÎ°ÄÌöåÎ•º Í∞úÏµúÌïòÍ≥†Ïûê 6Ïõî 10ÏùºÏûêÎ°ú ÏßëÌöåÍ≥µÍ≥†Î•º ÌïòÏòÄÏäµÎãàÎã§. 6Ïõî 14Ïùº Ïù¥ÎåÄÏõÖ ÏùòÏõêÎãò Ïô∏ 2Î∂ÑÏùò ÏùòÏõêÎãòÏúºÎ°ú ÌôòÍ≤ΩÎ∂ÑÏïº ÌòÑÏßÄÌôïÏù∏ ÌäπÎ≥ÑÏúÑÏõêÌöå Íµ¨ÏÑ± Í≤∞ÏùòÏïàÏù¥, ÏÜêÎã¨ÏÑ≠ ÏùòÏõêÎãò Ïô∏ 2Î∂ÑÏùò ÏùòÏõêÎãòÏúºÎ°úÎ∂ÄÌÑ∞ Ï†ú234Ìöå ÏûÑÏãúÌöå Ïãú ÌôúÎèôÌïú Ï£ºÏöîÏÇ¨ÏóÖ ÌòÑÏßÄÌôïÏù∏ Í≤∞Í≥º Î≥¥Í≥†Ïùò Í±¥Ïù¥ Í∞ÅÍ∞Å Ï†ëÏàòÎêòÏóàÏäµÎãàÎã§. ÏùåÏÑ±Íµ∞ÏàòÎ°úÎ∂ÄÌÑ∞ 20\n","630\n","512\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3a_67Z2UZbyo","executionInfo":{"status":"ok","timestamp":1633258307789,"user_tz":-540,"elapsed":1348,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"af0b66bf-00ca-4b50-f9a5-bf75656e47df"},"source":["summarization(199)"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'context': 'Ï∂ïÏÇ∞ÏãùÌíàÍ≥ºÏû• ÏÜ°ÏöîÏÑ±ÏûÖÎãàÎã§. Ï∂ïÏÇ∞ÏãùÌíàÍ≥º ÏÜåÍ¥Ä 2020ÎÖÑÎèÑ Íµ∞Ï†ïÏ£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖÏùÑ Î≥¥Í≥†ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. ÏÉÅÎ∞òÍ∏∞ Ï£ºÏöîÏóÖÎ¨¥ Ïã§Ï†ÅÏùÄ ÏÑúÎ©¥ÏúºÎ°ú Í∞àÏùåÌïòÍ≥†, Í∏∞Î≥∏ÌòÑÌô©, Íµ∞Ï†ï Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ ÏàúÏúºÎ°ú Î≥¥Í≥†ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. („Äå2020ÎÖÑÎèÑ Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ„Äç Î∂ÄÎ°ùÏóê Ïã§Ïùå) Ïù¥ÏÉÅÏúºÎ°ú Ï∂ïÏÇ∞ÏãùÌíàÍ≥º ÏÜåÍ¥Ä 2020ÎÖÑÎèÑ Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ Î≥¥Í≥†Î•º ÎßàÏπòÍ≤†ÏäµÎãàÎã§. Î≥¥Í≥†Î•º Îì§ÏúºÏãúÍ≥† ÏßàÏùòÌïòÏã§ ÏùòÏõêÎãò Í≥ÑÏãúÎ©¥ ÏßàÏùòÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÍπÄÏòÅÌò∏ ÏùòÏõêÎãò ÏßàÏùòÌïòÏó¨ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Í≥ºÏû•Îãò ÏÑ§Î™ÖÌïòÏãúÎäêÎùºÍ≥† ÏàòÍ≥†ÌïòÏÖ®ÏäµÎãàÎã§. ÏïÖÏ∑®Ìè¨ÏßëÏ∞®ÎüâÏùÄ Ï∂ïÏÇ∞ÏãùÌíàÍ≥ºÌïòÍ≥† Í¥ÄÎ†®Ïù¥ ÏóÜÎÇòÏöî? Ïòà, Ï†ÄÌù¨ÌïòÍ≥† Í¥ÄÎ†®Ïù¥ ÏóÜÍ≥† ÌôòÍ≤ΩÍ≥ºÏóêÏÑú Í¥ÄÎ¶¨ÌïòÍ≥† ÏûàÏäµÎãàÎã§, Ï≤≠ÏÜåÏúÑÏÉùÍ≥ºÌïòÍ≥†. ÏïÖÏ∑®Í∞Ä Ïã¨ÌïòÍ≤å ÎÇòÎäî ÏùºÎ∂Ä ÏñëÎèàÎÜçÏû• Ïù¥Îü∞ Ï™ΩÏóê ÏïÖÏ∑®Ìè¨ÏßëÏ∞®ÎüâÏùÑ ÌôúÏö©Ìï† Í≥ÑÌöçÏùÄ ÏóÜÎÇòÏöî? Ï†ÄÌù¨Í∞Ä ÏïåÍ∏∞Î°úÎäî ÎØºÏõêÏù¥ ÏûàÎäî ÏñëÎèàÎÜçÍ∞ÄÏóê ÌôòÍ≤ΩÍ≥ºÏóêÏÑú Î∞∞ÏπòÌï¥ÏÑú Ìè¨ÏßëÌïú Í≤ÉÏúºÎ°ú ÏïåÍ≥† ÏûàÏäµÎãàÎã§. ÎØºÏõêÏù¥ Ï†ëÏàòÎêòÎ©¥ Î∞∞ÏπòÌï† Ïàò ÏûàÎã§ Ïù¥Îü∞ ÏñòÍ∏∞Ï£†? ÏûêÏÑ∏Ìïú Í≥ÑÌöçÍπåÏßÄÎäî Ï†ÄÌù¨ Í≥ºÏóêÏÑúÎäî Ïûò Î™®Î•¥Í≤†ÏäµÎãàÎã§. Ïòà, ÌôòÍ≤ΩÍ≥ºÏóêÏÑú‚Ä¶‚Ä¶. Ïñ¥Ï®åÎì† ÏñëÎèàÎÜçÍ∞ÄÏóêÏÑú Î∞úÏÉùÎêòÎäî ÏïÖÏ∑®Î°ú Ïù∏Ìïú ÎØºÏõêÏù¥ ÎÅäÏù¥ÏßÄ ÏïäÎäî Í≤å ÌòÑÏã§Ïù∏Îç∞ ÏßÄÏÜçÏ†ÅÏúºÎ°ú ÎÉÑÏÉàÍ∞Ä Îçú ÎÇ† Ïàò ÏûàÍ≤åÎÅî ÎØ∏ÏÉùÎ¨ºÏù¥ÎÇò Ïù¥Îü∞ Í≤ÉÏùÑ Ï∂ïÏÇ∞ÏãùÌíàÍ≥ºÏóêÏÑúÎèÑ ÎßéÏù¥ Ïã†Í≤Ω Ïì∞Í≥† ÏûàÎäî Í±∞Ï£†? Ïòà, Í∑∏Î†áÏäµÎãàÎã§. Í∑∏Îü∞ Ï™ΩÏúºÎ°ú Ìï¥ÏÑú ÎÉÑÏÉàÍ∞Ä Îçú ÎÇ† Ïàò ÏûàÍ≤å ÎÖ∏Î†•ÏùÑ Ìï¥ Ï£ºÏãúÍ∏∏ Î∞îÎùºÎ©¥ÏÑú, Ïö∞Îú∏ÌïúÏö∞ÏÇ¨ÏóÖÏù¥ÎùºÎäî Í±∏ ÏïåÍ≥† Í≥ÑÏãúÏ£†? Ï∞∏Ïö∞Îú∏ÏÇ¨ÏóÖ ÏïåÍ≥† ÏûàÏäµÎãàÎã§. Ï∞∏Ïö∞Îú∏ÏÇ¨ÏóÖ. Í∑∏ Î∂ÄÎ∂ÑÏóê ÎåÄÌï¥ÏÑúÎäî Ïó¨Í∏∞ Í±∞Î°†Ïù¥ Ï†ÑÌòÄ Ïïà Îèº ÏûàÎäîÎç∞ ÏòàÏÇ∞ÏùÑ ÏäπÏù∏Ìï¥ Ï§¨Îçò Í≤ÉÏúºÎ°ú Í∏∞ÏñµÌïòÎäîÎç∞ ÌòÑÏû¨ ÏÇ¨ÏóÖÏù¥ Ïñ¥ÎñªÍ≤å ÏßÑÌñâÎêòÍ≥† ÏûàÏúºÎ©∞ ÏòàÏÇ∞Î∂ÄÎ∂ÑÏù¥ÎÇò Ïù¥Îü∞ Í≤å Î™®ÏûêÎùºÏßÄÎäî ÏïäÎäîÏßÄ Ïù¥Îü∞ Î∂ÄÎ∂ÑÎèÑ ÌïúÎ≤à ÏÑ§Î™ÖÏùÑ Ìï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. ÏßÄÍ∏à Ï∞∏Ïö∞Îú∏ÏÇ¨ÏóÖÏùÄ Ï∂ïÌòëÏóêÏÑú ÏßÑÌñâÏùÑ ÌïòÍ≥† ÏûàÏäµÎãàÎã§. Ï†ÄÌù¨Í∞Ä Ï∂ïÌòë Ïù¥Î¶ÑÏúºÎ°ú Ìï¥ÏÑú ÌïòÍ≥† ÏûàÎäîÎç∞ ÏÇ¨ÏóÖÎπÑÎäî ÏµúÏÉÅÍ∏∞ ÌåÄÏû•ÎãòÏù¥ ÏûêÏÑ∏Ìïú Í≤É Ï¢Ä ÏÑ§Î™ÖÌï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Ï∂ïÏÇ∞ÏãùÌíàÍ≥º ÎÜçÏ∂ïÏÇ∞ÏãùÌíàÌåÄÏû• ÏµúÏÉÅÍ∏∞ÏûÖÎãàÎã§. Î∞©Í∏à ÏùòÏõêÎãòÍªòÏÑú ÎßêÏîÄÌïòÏã† Ï∞∏Ïö∞Îú∏ÏÇ¨ÏóÖÏùÄ ÎãπÏ¥à Ï†ÄÌù¨Í∞Ä Íµ∞ 50%, Ï∂ïÌòë 50% Ìï¥ÏÑú Ï¥ù 4,800ÎßåÏõê ÏòàÏÇ∞Í∞ÄÏßÄÍ≥† 1ÎÖÑÍ∞Ñ Í¥ÄÎÇ¥ ÏÜå ÎèÑÏ∂ïÎ∂ÑÏóê ÎåÄÌï¥ÏÑú ÎëêÎãπ 20ÎßåÏõêÏî© ÏßÄÏõêÌïòÎäî ÏÇ¨ÏóÖÏúºÎ°ú Ï∂îÏßÑÌïòÍ≥† ÏûàÏäµÎãàÎã§. Í∑∏ÎûòÏÑú ÌòÑÏû¨ Î∂ÑÍ∏∞Î≥ÑÎ°ú Ï†ÄÌù¨Í∞Ä Ï∂îÏßÑÏã§Ï†ÅÏùÑ ÌïòÍ≥† ÏûàÎäîÎç∞ ÏÉÅÎ∞òÍ∏∞Ïóê 1Ìöå ÏßÄÍ∏âÌñàÍ≥†Ïöî, Î¨ºÎ°† ÏÉÅÎ∞òÍ∏∞Ïóê ÏΩîÎ°úÎÇò ÎïåÎ¨∏Ïóê ÏÇ¨ÏóÖÏù¥ ÏßÄÎÇúÌïòÍ≥† Í∑∏ÎßåÌÅº ÌåêÎß§Í∞Ä Ïïà ÎèºÏÑú ÏïûÏúºÎ°ú ÎÇòÎ®∏ÏßÄ ÏòàÏÇ∞Ïóê ÎåÄÌï¥ÏÑúÎäî ÏÜåÏßÑÌï† Ïàò ÏûàÎèÑÎ°ù Ï†ÅÍ∑πÏ†ÅÏúºÎ°ú ÏÇ¨ÏóÖÏùÑ Ï∂îÏßÑÌïòÎèÑÎ°ù ÌïòÍ≤†ÏäµÎãàÎã§. ÏÇ¨Ïã§ ÏùåÏÑ±Íµ∞Ïùò ÌïúÏö∞Î•º Î∏åÎûúÎìúÌôîÌïòÍ≥† Ïú°ÏÑ±ÌïòÍ∏∞ ÏúÑÌï¥ÏÑú Ï∞∏Ïö∞Îú∏ÏÇ¨ÏóÖÏùÑ ÌïòÎäî Í≤ÉÏúºÎ°ú ÏïåÍ≥† ÏûàÎäîÎç∞ Ìïú 3ÎÖÑ Ï†ïÎèÑ ÎêêÏ£†? Ïòà, Í∑∏ Ï†ïÎèÑ ÎêêÏäµÎãàÎã§. Í∑∏Îü∞Îç∞ ÏßÄÍ∏àÍπåÏßÄ Ìïú Î≤àÎèÑ ÏùòÌöåÏóê Î≥¥Í≥†Ìïú Í≤å ÏóÜÎäî Í≤É Í∞ôÏïÑÏöî. Í∑∏ÎûòÏÑú ÏßàÏùòÎ•º ÎìúÎ†∏Í≥†, Ïù¥ Î∂ÄÎ∂ÑÏù¥ ÌôúÏÑ±ÌôîÍ∞Ä ÎèºÏÑú Ïö∞Î¶¨ ÏùåÏÑ±Íµ∞ ÌïúÏö∞ÎèÑ Í∑∏ÏïºÎßêÎ°ú Î∏åÎûúÎìúÌôîÍ∞Ä Îê† Ïàò ÏûàÍ≤åÎÅî ÎßéÏù¥ ÎÖ∏Î†•ÏùÑ Ìï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Í∑∏Î¶¨Í≥† Î≥∏ ÏùòÏõêÏù¥ ÏÉùÍ∞ÅÌïòÍ∏∞Ïóê ÏåÄÏù¥ÎÇò Ï∞∏Ïö∞Îú∏ÌïúÏö∞ Ïù¥Ï™ΩÎèÑ Î≥¥Î©¥ Îã§ ÎÜçÌòëÏù¥ÎÇò Ï∂ïÌòë Ï™ΩÏóê ÏúÑÌÉÅÏùÑ Ìï¥ÏÑú ÏÇ¨ÏóÖÏùÑ Ìï¥Ïöî. Í∑∏Îü¨Îã§ Î≥¥ÎãàÍπå Í∑∏Ïóê Îî∞Î•∏ ÌèêÎã®Ïù¥ ÎßéÏù¥ Î∞úÏÉùÎêòÍ≥† ÏûàÎäîÎç∞ Ïö∞Î¶¨ Ï∂ïÏÇ∞ÏãùÌíàÍ≥ºÏóêÏÑú ÎßéÏù¥ Ïã†Í≤ΩÏùÑ Ïç®ÏÑú ÏßÄÎèÑÎ•º Ìï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Ïûò ÏïåÍ≤†ÏäµÎãàÎã§. Ïù¥ÏÉÅÏûÖÎãàÎã§. Îòê ÏßàÏùòÌïòÏã§ ÏùòÏõêÎãò Í≥ÑÏã≠ÎãàÍπå? ÏÑúÌö®ÏÑù ÏùòÏõêÎãò ÏßàÏùòÌï¥ Ï£ºÏãúÍ∏∞ Î∞îÎûçÎãàÎã§. Í≥ºÏû•Îãò ÏûêÎ£å Ï§ÄÎπÑÌïòÍ≥† ÏÑ§Î™ÖÌïòÏãúÎäêÎÉêÍ≥† ÏàòÍ≥†ÌïòÏã≠ÎãàÎã§. 9Ï™Ω Í¥ÄÎ†®Ìï¥ÏÑú ÏßàÏùòÎìúÎ¶¨Í≤†ÏäµÎãàÎã§. Ìá¥ÎπÑÎ∂ÄÏàôÎèÑ Í≤ÄÏÇ¨ ÏùòÎ¨¥Ìôî ÏßÄÏõêÏÇ¨ÏóÖ Ïûò ÌïòÍ≥† Í≥ÑÏãúÎäîÎç∞ ÌïòÎã®Ïóê Î≥¥Î©¥ Î∂ÄÏàôÎèÑÍ≤ÄÏÇ¨ Ï∂îÏßÑÏã§Ï†Å Ìï¥ÏÑú 205Ìò∏ Ïù¥Î†áÍ≤å ÌïòÏÖ®Îã§Í≥† ÌñàÎäîÎç∞ Ïó¨Í∏∞ÏóêÏÑú ÌòπÏãú ÏúÑÎ∞òÎêòÍ±∞ÎÇò Í≥ºÌÉúÎ£åÎ•º Î∂ÄÍ≥ºÌïú Í≤ΩÏö∞Í∞Ä ÏûàÎÇòÏöî? ÏïÑÏßÅÍπåÏßÄÎäî ÏïÑÎãàÍ≥† ÎÇ¥ÎÖÑ 3Ïõî 24ÏùºÍπåÏßÄÎäî Ïú†ÏòàÍ∏∞Í∞ÑÏù¥Í≥† Î∂ÄÏàôÎèÑÍ≤ÄÏÇ¨Îäî ÎÜçÏóÖÍ∏∞Ïà†ÏÑºÌÑ∞ÏóêÏÑú Í≤ÄÏÇ¨Í∏∞Í≥ÑÍ∞Ä ÏûàÏäµÎãàÎã§. Í∑∏Îü∞Îç∞ Ï†ÄÌù¨Í∞Ä 1Ï∞® Í≤ÄÏÇ¨Ìïú Í≤∞Í≥º 95% Ïù¥ÏÉÅ Ìï©Í≤©Ïù¥ ÎêòÍ≥† ÏûàÏäµÎãàÎã§. ÌòÑÏû¨ Í∑∏Î†áÍ≤å ÎÜíÍ≤å Ìï©Í≤©Î•†Ïù¥ ÎÇòÏò§Í≥† ÏûàÏäµÎãàÍπå? Ïö∞Î¶¨Í∞Ä ÎÇòÍ∞ÄÏÑú ÌïòÎäî Í≤å ÏïÑÎãàÍ≥† Î≥∏Ïù∏Îì§Ïù¥ Í∞ÄÏßÄÍ≥† ÏôÄÏÑú Í≤ÄÏÇ¨ÏùòÎ¢∞Î•º ÌïòÎäîÎç∞ 95% Ïù¥ÏÉÅ Ìï©Í≤©Î•†Ïù¥ ÎÇòÏò§Í≥† ÏûàÏäµÎãàÎã§. ÏûêÍ∞ÄÍ≤ÄÏÇ¨Î°ú ÌïúÎã§Îäî Í±∞Ï£†? Î≥∏Ïù∏Îì§Ïù¥ Í∞ÄÏßÄÍ≥† ÏôÄÏÑú ÎÜçÏóÖÍ∏∞Ïà†ÏÑºÌÑ∞ÏóêÏÑú ÏùòÎ¢∞Î•º ÌïòÎäî Í≤ÅÎãàÎã§. Î≥∏Ïù∏Îì§Ïù¥ Í∑∏Í≤ÉÏùÑ Ï±ÑÏ∑®Ìï¥Í∞ñÍ≥† ÏôÄÏÑú ÏßÅÏ†ë ÌïòÏã†Îã§Îäî ÎßêÏîÄÏù¥ÏãúÏ£†? Ïòà. Í∑∏ÎûòÏÑú Ïù¥Í≤å Ïñ¥Ï®åÎì† Í∏àÎÖÑÎ∂ÄÌÑ∞ ÏùòÎ¨¥ÏÇ¨Ìï≠ÏúºÎ°ú ÎêêÏúºÎãàÍπå Í≥ÑÎèÑÍ∏∞Í∞ÑÏóê Ï∂©Î∂ÑÌûà Í≥ÑÎèÑÎ•º ÏûòÌïòÏÖîÏÑú ÎÇòÏ§ëÏóê Í≥ºÌÉúÎ£åÎùºÎì†Í∞Ä Ïñ¥Îñ§ Î∂àÏù¥ÏùµÏùÑ Î∞õÏßÄ ÏïäÍ≤åÎÅî Í∑∏Î†áÍ≤å ÎÖ∏Î†•ÏùÑ Ìï¥Ï£ºÏãúÍ≥†Ïöî. 16Ï™Ω Í¥ÄÎ†®Ìï¥ÏÑú ÎèôÎ¨º Î≥µÏßÄÏÇ¨ÏóÖ ÌôïÎåÄ Ìï¥ÏÑú Í∏∏Í≥†ÏñëÏù¥ Ï§ëÏÑ±ÌôîÏÇ¨ÏóÖÏùÑ Ìïú 40Îëê Ï†ïÎèÑ Í≥ÑÌöçÏùÑ ÌñàÎäîÎç∞ 12% Ï†ïÎèÑ Ìïú Í≤É Í∞ôÏùÄÎç∞ Í∏∏Í≥†ÏñëÏù¥Í∞Ä ÍµâÏû•Ìûà ÎßéÏßÄ ÏïäÎÇòÏöî? ÏßÄÍ∏à ÏÉÅÎãπÌûà ÎßéÏù¥ ÏûàÏäµÎãàÎã§. Í∑∏Îü∞Îç∞ Ï†ÄÌù¨Í∞Ä Ï†ïÌôïÌïú ÎßàÎ¶øÏàòÎäî ÌååÏïÖÏù¥ Ïïà ÎêòÍ≥† ÏûàÏäµÎãàÎã§. 40ÎëêÎäî ÌòÑÏû¨ ÏûàÎäî Í≤ÉÎ≥¥Îã§ Ìõ®Ïî¨ Ï†ÅÏùÄ Ïàò Í∞ôÏùÄÎç∞ÎèÑ Î∂àÍµ¨ÌïòÍ≥† ÏßÄÍ∏à Ïù¥Í≤É Í≥µÏ†ïÎ•†ÏùÑ Î≥¥Î©¥ ÍµâÏû•Ìûà Ï†ÄÏ°∞Ìïú Í≤É Í∞ôÏäµÎãàÎã§. Ïù¥Î†áÍ≤å Ï†ÄÏ°∞Ìïú Í≤ÉÏùÄ ÌäπÎ≥ÑÌïú Ïù¥Ïú†Í∞Ä ÏûàÎÇòÏöî? ÏßÄÍ∏à Ï†ÄÌù¨ÌïúÌÖå Ïã†Í≥† Îì§Ïñ¥Ïò§Îäî Í≤É ÏúÑÏ£ºÎ°ú ÌïòÍ≥† ÏûàÎäîÎç∞ Í∏∏Í≥†ÏñëÏù¥Î•º ÏùºÎ∂Ä Í¥ÄÏã¨ ÏûàÎäî Î∂ÑÎì§Îßå Ïã†Í≥†Î•º ÌïòÍ≥† ÎÇòÎ®∏ÏßÄÎäî Ïã†Í≥†Í∞Ä Ïïà ÎêòÍ≥† ÏûàÏñ¥ÏÑú ÏÇ¨ÏóÖ ÏûêÏ≤¥Í∞Ä Ï†ÄÏ°∞Ìï©ÎãàÎã§. Ï†ÄÌù¨Í∞Ä Î≥ÑÎèÑÏùò Ïñ¥Îñ§ Ïù∏Í±¥ÎπÑÎÇò ÏàòÎãπ Í∞ôÏùÄ Í≤ÉÏùÑ Ï£ºÏßÄ ÏïäÍ≥† Ïã†Í≥† Îì§Ïñ¥Ïò§Îäî Í≤ÉÏóêÏÑúÎßå Í∞ÄÏÑú ÏÇ¨ÏóÖÏùÑ ÌïòÍ≥† ÏûàÎã§Îäî ÎßêÏîÄÏù¥Ïã†Í∞ÄÏöî? ÎèôÎ¨ºÎ≥ëÏõêÌïòÍ≥† ÌòëÏïΩÏùÑ Ìï¥ÏÑú Í∑∏Ï™ΩÏúºÎ°ú ÏúÑÌÉÅÌï¥ÏÑú ÌïòÍ≥† ÏûàÏäµÎãàÎã§. ÏïåÍ≤†ÏäµÎãàÎã§. ÌïòÏó¨Í∞Ñ Ïù¥Í≤å Ï†ÄÌù¨ Ï£ºÎ≥ÄÎßå Ìï¥ÎèÑ ÏßÄÍ∏à ÎßàÎ¶øÏàòÍ∞Ä ÍµâÏû•Ìûà ÎßéÏùÄ Í≤É Í∞ôÏùÄÎç∞ Ïù¥Îü∞ Î∂ÄÎ∂ÑÏùÄ Ï†ÅÍ∑πÌñâÏ†ïÏùÑ Ï∑®Ìï¥Ïïº Îê† Í≤É Í∞ôÏùÄÎç∞ ÏÉùÍ∞ÅÎ≥¥Îã§ ÎπÑÏú®Ïù¥ ÍµâÏû•Ìûà ÎÇÆÏïÑÏÑú ÌïúÎ≤à ÏßàÏùòÎìúÎ†∏ÏäµÎãàÎã§. Îçî ÎÖ∏Î†•ÏùÑ ÌïòÍ≥† ÌôçÎ≥¥Ìï¥ÏÑú Í∑∏ ÏÇ¨ÏóÖÏù¥ Ï∂îÏßÑÏù¥ Îê† Ïàò ÏûàÎèÑÎ°ù ÌïòÍ≤†ÏäµÎãàÎã§. Í∑∏Î¶¨Í≥† 19Ï™Ω ÏπúÌôòÍ≤Ω Î°úÏª¨Ìë∏Îìú Îß§Ïû•ÏùÑ Ï°∞ÏÑ±ÏùÑ ÌïòÏãúÎäîÎç∞ ÏïÑÍπå ÎÜçÏ†ïÍ≥ºÏóêÎèÑ ÌïúÎ≤à ÏßàÏùòÎ•º ÌïòÍ≥† Ïã∂ÏóàÎäîÎç∞ Ïó¨Í∏∞ÏÑú Í≤πÏπòÎäî Í≤É Í∞ôÏïÑÏÑú ÏßàÏùòÎ•º Ïïà ÎìúÎ†∏ÎäîÎç∞ ÌòÑÏû¨ Í≥†Ï∂ßÍ∞ÄÎ£®Í∞ÄÍ≥µÏãúÏÑ§Ïù¥ Íµ∞ÏóêÏÑú Í¥ÄÎ¶¨ÏúÑÌÉÅÏùÑ Ï§òÏÑú ÏùåÏÑ±Ï≤≠Í≤∞Í≥†Ï∂ßÍ∞ÄÎ£®Î•º ÏÉùÏÇ∞ÏùÑ ÌïòÍ≥† ÏûàÎäîÎç∞ Î°úÏª¨Ìë∏ÎìúÎß§Ïû•Ïù¥ÎùºÎì†Í∞Ä ÌäπÌûà ÎÜçÌòëÏùÑ Ï§ëÏã¨ÏúºÎ°ú ÌïòÎäî ÎßàÌä∏ÏóêÏÑú ÏùåÏÑ±Í≥†Ï∂ßÍ∞ÄÎ£®Î•º ÌåêÎß§Î•º ÌïòÍ≥† ÏûàÎÇòÏöî? Í≥†Ï∂ßÍ∞ÄÎ£®ÎèÑ ÌåêÎß§Î•º ÌïòÍ≥† ÏûàÏäµÎãàÎã§. Î≥∏ ÏùòÏõêÏù¥ ÌòÑÏû•Ïóê Í∞îÏùÑ Îïå ÏùåÏÑ±Ï≤≠Í≤∞Í≥†Ï∂ßÍ∞ÄÎ£®Î•º ÌåêÎß§Î•º Ïïà ÌïòÎäî Îß§Ïû•Ïù¥ Îçî ÎßéÏïòÎçò Í≤É Í∞ôÏäµÎãàÎã§. Í∑∏Î¶¨Í≥† ÌäπÌûà Îã§Î•∏ ÏßÄÏó≠ Í≤ÉÏù¥ Îçî ÎßéÏù¥ ÏßÑÏó¥Ïù¥ ÎêòÏñ¥ ÏûàÏóàÎäîÎç∞ Í∑∏Îü∞ Î∂ÄÎ∂ÑÏùÑ Ïñ¥ÎñªÍ≤å Í∞úÏÑ†Ìï† Ïàò ÏûàÎäî Î∞©Î≤ïÏù¥ ÏóÜÎÇòÏöî? Ï†ÄÌù¨Í∞Ä ÏßÄÍ∏à Í¥ÄÎÇ¥ ÏÉùÏÇ∞ ÎÜçÏÇ∞Î¨ºÏùÑ ÏúÑÏ£ºÎ°ú ÌïòÍ≥† ÏûàÎäîÎç∞ Ï†ÄÌù¨ Î°úÏª¨Ìë∏ÎìúÎß§Ïû•ÏùÄ Í¥ÄÎÇ¥ ÎÜçÏÇ∞Î¨ºÎßå Îì§Ïñ¥Ïò§Í≥† ÏûàÏäµÎãàÎã§. Î°úÏª¨Ìë∏ÎìúÎß§Ïû• Ïô∏Ïóê ÎÜçÌòëÏùÄ ÏÇ¨Ïã§ Í¥ÄÎÇ¥ ÎÜçÏÇ∞Î¨º ÏúÑÏ£ºÎ°ú Ï∑®Í∏âÏùÑ ÌïòÎäî Í±∏Î°ú ÏÉÅÏãùÏ†ÅÏúºÎ°ú ÏÉùÍ∞ÅÏùÑ ÌïòÎäîÎç∞ Í±∞Í∏∞Ïóê Îã§Î•∏ Í≤ÉÏùÄ ÎëòÏß∏ ÏπòÍ≥† Í≥†Ï∂ßÍ∞ÄÎ£®Í∞ÄÍ≥µÏãúÏÑ§ÏùÄ Íµ∞ÏóêÏÑú ÏßÄÏõêÏùÑ Ìï¥ÏÑú Í¥ÄÎ¶¨ÏúÑÌÉÅÎßå ÌïòÎäî Í±∞ÏßÄ Ïã§ÏßàÏ†ÅÏúºÎ°ú ÏùåÏÑ±Íµ∞ Í≥†Ï∂ßÍ∞ÄÎ£®Î•º ÌåêÎß§Î•º ÌïòÎäî Í±∞ÏòàÏöî. Í∑∏ÎûòÏÑú Ïù¥Îü∞ Î∂ÄÎ∂ÑÏùÄ ÎÜçÌòëÌïòÍ≥† ÌòëÏùòÎ•º Ìï¥ÏÑú ÏßÑÏó¥Ïù¥ ÎèºÏÑú ÌåêÎß§Î•º Ìï† Ïàò ÏûàÍ≤åÎÅî Ï†ÅÍ∑πÏ†ÅÏúºÎ°ú Ìï¥Ï£ºÏÖ®ÏúºÎ©¥ ÌïòÎäî Î∂ÄÌÉÅÏùÑ ÎìúÎ¶ΩÎãàÎã§. Ïòà, ÏïåÍ≤†ÏäµÎãàÎã§. ÏßÄÎÇúÌï¥, ÏßÄÏßÄÎÇúÌï¥Ïóê Í≥ÑÏÜçÌï¥ÏÑú ÎßêÏîÄÏùÑ ÎìúÎ†∏Í≥† ÏûêÎ£åÍπåÏßÄ ÏöîÏ≤≠ÏùÑ ÌñàÏóàÎäîÎç∞ Í∞úÏÑ†Ïù¥ ÎêêÎã§Í≥† Ìï¥ÏÑú Î≥∏ ÏùòÏõêÏù¥ ÌïúÎ≤à Îß§Ïû•ÏùÑ ÎèåÏïòÎäîÎç∞ Í∞úÏÑ†Ïù¥ Ïïà Îêú Í≤É Í∞ôÏäµÎãàÎã§. Î≥∏Ïù∏Ïù¥ Í∞îÏùÑ Îïå Í∑∏ Ï†úÌíàÏù¥ ÏóÜÏóàÎäîÏßÄÎäî Î™®Î•¥Í≤†ÏßÄÎßå ÌïòÏó¨Í∞Ñ Í∑∏Îü∞ Î∂ÄÎ∂Ñ Ï°∞Í∏à Îçî Ïã†Í≤ΩÏùÑ Ïç®Ï£ºÏÖ®ÏúºÎ©¥ ÌïòÎäî Î∂ÄÌÉÅÏùÑ ÎìúÎ¶¨Í≥†Ïöî. Í∑∏Îã§ÏùåÏóê Î¨¥ÏÉÅÍ∏âÏãù ÌôïÎåÄÎùºÎì†Í∞Ä ÌïôÍµêÍ∏âÏãù ÏïàÏ†ïÌôî ÏßÄÏõê ÏÇ¨ÏóÖÏóêÏÑú ÏßÄÎÇúÌï¥ Î°úÏª¨Ìë∏Îìú ÎÜçÍ∞ÄÍµêÏú°ÏùÑ 9Í∞ú ÏùçÎ©¥ÏùÑ Îã§ ÏàúÌöåÌï¥ÏÑú ÌïòÏÖ®Ï£†? Ïòà. ÎÜçÍ∞ÄÍ∞Ä ÎßéÏù¥ Ï∞∏Ïó¨Î•º ÌñàÎÇòÏöî? ÏßÄÍ∏à ÌòÑÏû¨ 250ÎÜçÍ∞Ä Ï†ïÎèÑ Ï∞∏Ïó¨ÌñàÏäµÎãàÎã§. 250ÎÜçÍ∞ÄÍ∞Ä Í∏∞Ï°¥Ïóê Ï∞∏Ïó¨Î•º Ïïà ÌñàÎçò ÎÜçÍ∞ÄÍ∞Ä Ï∞∏Ïó¨Î•º Ìïú Í±∞ÏòàÏöî? Í∞ôÏù¥ Ïó∞Í≤∞Ïù¥ Îêú Í≤ÅÎãàÎã§. Í∏∞Ï°¥Ïùò ÌïôÍµêÍ∏âÏãùÏóê Ï∞∏Ïó¨Î•º ÌñàÎçò ÎÜçÍ∞ÄÎäî Ìïú 50~60ÎÜçÍ∞ÄÎèÑ Ïïà ÎêêÎçò Í±∏Î°ú Î≥∏ ÏùòÏõêÏù¥ ÌååÏïÖÏùÑ ÌñàÏóàÎäîÎç∞. ÏßÄÍ∏àÏùÄ Îã§Î•∏ ÎÜçÌòëÌïòÍ≥† Ïó∞Í≥ÑÍ∞Ä ÎêòÍ≥† ÌôïÎåÄÎ•º ÏãúÏºúÏÑú 250ÎÜçÍ∞Ä Ï†ïÎèÑÍ∞Ä‚Ä¶‚Ä¶. 250Ïó¨ ÎÜçÍ∞ÄÍ∞Ä ÎêêÎäîÎç∞ ÏûêÎ£åÏóê Î≥¥Î©¥ ÏπúÌôòÍ≤Ω ÎÜçÏÇ∞Î¨ºÏù¥ Ï¶ùÍ∞ÄÎêú Í≤å ÏßÄÎÇúÌï¥ÌïòÍ≥† ÏßÄÍ∏àÌïòÍ≥† 1.09%ÏòàÏöî. 1% Ï†ïÎèÑÎ∞ñÏóê Ï¶ùÍ∞ÄÍ∞Ä Ïïà ÎêêÏäµÎãàÎã§. ÏßÄÎÇúÌï¥ 1ÎÖÑ ÎèôÏïà Î°úÏª¨Ìë∏Îìú ÌôçÎ≥¥ÌïòÍ≥† Ï∞∏Ïó¨ÎÜçÍ∞Ä ÌôïÎåÄÌïòÍ≥† ÌñàÎäîÎç∞ Ïã§ÏßàÏ†ÅÏúºÎ°ú ÌòÑÏû•ÏóêÏÑúÎäî ÎäòÏñ¥ÎÇú Í≤å Í±∞Ïùò ÏóÜÎäî Í≤É Í∞ôÏäµÎãàÎã§. Ïñ¥Îñ§ ÌäπÎ≥ÑÌïú Ïù¥Ïú†Í∞Ä ÏûàÎÇòÏöî? ÏßÄÍ∏à ÌïôÍµêÍ∏âÏãùÏù¥ Ïïà ÎêòÍ≥† Í∑∏Îü¨Îã§ Î≥¥ÎãàÍπå Ïã§Ï†úÎ°ú ÎπÑÏú® ÏûêÏ≤¥Í∞Ä ÎäòÏñ¥ÎÇòÏßÄÎ•º ÏïäÏïòÏäµÎãàÎã§. Ï†ÄÌù¨Í∞Ä ÏΩîÎ°úÎÇò ÎïåÎ¨∏Ïóê ÌïôÍµêÍ∏âÏãùÏù¥ Ïïà ÎêòÎã§ Î≥¥ÎãàÍπå Î¨ºÎüâ ÏûêÏ≤¥Í∞Ä Ï§ÑÏñ¥Îì§ÏóàÍ∏∞ ÎïåÎ¨∏Ïóê ÏùåÏÑ±ÏÇ∞ ÎÜçÏÇ∞Î¨ºÏù¥ÎÇò ÏπúÌôòÍ≤ΩÎÜçÏÇ∞Î¨ºÏù¥ ÌÅ¨Í≤å ÎäòÏßÄÎ•º ÏïäÏïòÏäµÎãàÎã§. Î¨ºÎüâÏù¥ Ï§Ä Í≤ÉÌïòÍ≥† Í∏àÏï° ÎåÄÎπÑ ÎπÑÏú®ÌïòÍ≥†Îäî ÌÅ∞ Ï∞®Ïù¥Í∞Ä ÏóÜÏùÑ Í≤É Í∞ôÏùÄÎç∞? ÏßÄÍ∏à Ïò¨Ìï¥ Í≥µÍ∏âÌïú Í≤å ÏùåÏÑ±ÏÇ∞ ÎÜçÏÇ∞Î¨ºÏù¥ 3,300ÎßåÏõê Ï†ïÎèÑ ÌñàÏßÄÎßå ÏûëÎÖÑÏóêÎäî 2Ïñµ ÏñºÎßà Ïù¥Î†áÍ≤å ÌñàÍ∏∞ ÎïåÎ¨∏Ïóê Î¨ºÎüâÏù¥ ÏõêÏ≤¥ Ï†ÅÏñ¥ÏÑú ÎπÑÏú®Ïù¥ Ïò¨ÎùºÍ∞à ÏàòÍ∞Ä ÏóÜÏóàÏäµÎãàÎã§. Ï†ïÏÉÅÏ†ÅÏúºÎ°ú Ï∂îÏßÑÎêúÎã§Î©¥ ÎπÑÏú®ÏùÄ ÏÉÅÎãπÌûà ÎÜíÏù¥ Ïò¨ÎùºÍ∞à Í±∞ÎùºÍ≥† ÏÉùÍ∞ÅÌï©ÎãàÎã§. ÏùåÏÑ±ÏÇ∞ ÎÜçÏÇ∞Î¨ºÎèÑ ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú Ìïú 2.4~2.5% Ï†ïÎèÑ Ï¶ùÏï°Ïù¥ ÎêêÎäîÎç∞ ÎÜçÏÇ∞Î¨º ÎßêÍ≥† Í≥µÏÇ∞ÌíàÏù∏ Í≤ΩÏö∞ ÏùåÏÑ±ÏßÄÏó≠ÏóêÏÑú ÎÇ©ÌíàÌïòÎäî ÎπÑÏú®Ïù¥ Ïñ¥Îäê Ï†ïÎèÑ ÎêòÏ£†? ÏßÄÍ∏à Ï†ÄÌù¨Í∞Ä Ìïú 20% Ï†ïÎèÑ Î≥¥Í≥† ÏûàÏäµÎãàÎã§. ÏßÄÏõê Ï°∞Î°ÄÏóêÎäî ÏßÄÏó≠ÏÉÅÍ∞ÄÏóêÏÑú ÌïòÍ≤åÎÅî, Î∞òÎìúÏãú Ìï¥Ïïº ÌïúÎã§Îäî ÏïÑÎãàÏßÄÎßå Í∑∏Î†áÍ≤å Ìï¥Ïïº ÎêúÎã§Í≥† ÌïòÎäî Í∑∏Îü∞ Ï°∞Ìï≠Ïù¥ ÏûàÏäµÎãàÎã§. Í∑∏Îü¨Î©¥ Ïù¥Îü∞ Î∂ÄÎ∂ÑÎèÑ ÎÜçÏÇ∞Î¨º Ïô∏Ïóê Í≥µÏÇ∞ÌíàÎèÑ ÎßàÏ∞¨Í∞ÄÏßÄÎ°ú ÎπÑÏú®ÏùÑ ÎÜíÏó¨Ïïº Îê† Í≤É Í∞ôÏäµÎãàÎã§. Ï†ÅÍ∑πÏ†ÅÏúºÎ°ú ÎÖ∏Î†•ÏùÑ Ìï¥ÏÑú Ïö∞Î¶¨ ÏùåÏÑ±Ï†úÌíàÍ≥º ÎÜçÏÇ∞Î¨ºÏù¥ ÎßéÏù¥ Í≥µÍ∏âÏù¥ Îê† Ïàò ÏûàÎèÑÎ°ù ÎÖ∏Î†•ÌïòÍ≤†ÏäµÎãàÎã§. Í∑∏Î¶¨Í≥† Îòê 1Í∞ÄÏßÄ ÏßÄÎÇúÌï¥ ÌïôÍµêÍ∏âÏãùÍ≥µÍ∏âÎã®Í∞ÄÏã¨ÏùòÏúÑÏõêÌöå Í∑∏Í≤ÉÏùÑ Î≥¥ÏôÑÏùÑ ÌñàÏúºÎ©¥ Ï¢ãÍ≤†Îã§Í≥† ÌñàÎäîÎç∞ Ïã¨ÏùòÏúÑÏõêÌöåÍ∞Ä Î≥¥ÏôÑÏù¥ ÎêêÎÇòÏöî? ÏïÑÏßÅ Î≥¥ÏôÑÏù¥ Ïïà ÎêêÏäµÎãàÎã§. 1Î™ÖÏù¥ Ï†ÄÌù¨Í∞Ä Ïã¨ÏùòÏúÑÏõêÌöåÏóê Î¨ºÌíàÏùÑ ÎÇ©ÌíàÌïòÍ≥† Í∑∏Îü¨Îäî Í≤å ÏûàÏñ¥ÏÑú ÏïÑÏßÅ Î™ª ÌïòÍ≥† ÏûàÏäµÎãàÎã§. ÌïôÍµêÍ∏âÏãùÏßÄÏõêÏã¨ÏùòÏúÑÏõêÌöåÌïòÍ≥† Í≥µÍ∏âÎã®Í∞ÄÏã¨ÏùòÏúÑÏõêÌöåÌïòÍ≥† ÏÑ±Í≤©Ïù¥ ÏôÑÏ†ÑÌûà Îã§Î•¥ÏûñÏïÑÏöî. ÏßÄÏõêÎã®Í∞ÄÏã¨ÏùòÏúÑÏõêÌöåÏóê Í∑∏ÎèôÏïà ÏÉùÏÇ∞ÏûêÎ•º ÎåÄÌëúÌïòÎäî ÏÇ¨ÎûåÏù¥ÎÇò ÏÉùÏÇ∞ÏûêÎì§Ïùò Î™©ÏÜåÎ¶¨Í∞Ä Îã¥Í≤®Ï†∏ ÏûàÏßÄ ÏïäÏïòÎçò Í≤É Í∞ôÏäµÎãàÎã§. Í∑∏ÎûòÏÑú Í∑∏ Î∂ÄÎ∂Ñ Ï°∞Í∏à Ï±ôÍ≤®ÏÑú Ìï¥Ï£ºÏÖ®ÏúºÎ©¥ ÌïòÎäî Î∞îÎûåÏù¥Í≥†. Îòê 1Í∞ÄÏßÄ, ÎÜçÏÇ∞Î¨ºÍæ∏Îü¨ÎØ∏ Í≥µÍ∏âÏÇ¨ÏóÖÏùÑ ÌñàÏóàÏûñÏïÑÏöî. Í∑∏Îü∞Îç∞ ÎßåÏïΩÏóê ÌòÑ ÏÉÅÌÉúÎ°ú ÏÇ¨ÌöåÏ†Å Í±∞Î¶¨ÎëêÍ∏∞ 2Îã®Í≥ÑÍ∞Ä 3Îã®Í≥ÑÎ°ú Í≤©ÏÉÅÏù¥ ÎêúÎã§Í±∞ÎÇò ÏïÑÎãàÎ©¥ Ïù¥ ÏÉÅÌÉúÍ∞Ä Í≥ÑÏÜç ÏßÄÏÜçÏù¥ Îê† Í≤ΩÏö∞ ÎÜçÏÇ∞Î¨ºÍæ∏Îü¨ÎØ∏ÏÇ¨ÏóÖÏùÑ Îòê Îã§Ïãú Ìï¥Ïïº ÎêòÎäî ÏÉÅÌô©Ïù¥ Î∞úÏÉùÌïòÏßÄ ÏïäÏùÑÍπåÏöî? ÌïôÍµêÍ∏âÏãùÏßÄÏõêÏã¨ÏùòÏúÑÏõêÌöåÎ•º Í±∞Ï≥êÏÑú Í∑∏Í≤ÉÎèÑ ÏÉùÍ∞ÅÏùÑ ÌïòÍ≥† ÏûàÏäµÎãàÎã§. Í∑∏Îü∞ Î∂ÄÎ∂ÑÏùÑ ÏõêÎßåÌûà ÌñàÏúºÎ©¥ ÌïòÎäî Î∂ÄÌÉÅÏùÑ ÎìúÎ¶¨Í≥†Ïöî. Í∑∏Îü∞ ÏÇ¨ÏóÖÏùÑ Ìï† Í≤ΩÏö∞ Ï†úÎïå Í≥µÍ∏âÏù¥ Ïïà ÎêòÍ≥† ÏÉùÎ¨ºÏù¥Îã§ Î≥¥ÎãàÍπå ÏÉÅÌíàÍ∞ÄÏπòÍ∞Ä Îñ®Ïñ¥Ï°åÎã§Í±∞ÎÇò ÏïΩÍ∞Ñ ÌõºÏÜêÏù¥ ÎêòÍ±∞ÎÇò Ïù¥Îü∞ Î∂ÄÎ∂ÑÏù¥ ÏûàÏóàÎçò Í≤É Í∞ôÏäµÎãàÎã§. Í∑∏ÎûòÏÑú ÏÇ¨Ï†ÑÏóê ÎØ∏Î¶¨ Ï§ÄÎπÑÎ•º Ìï¥ÏÑú Ï†ÅÍ∏∞Ïóê Ïù¥Í≤å Î∞∞ÏÜ°Ïù¥ ÎèºÏïº ÏÉÅÌíàÍ∞ÄÏπòÍ∞Ä ÏûàÍ≥† Í≥†ÎßôÎã§Îäî ÏÉùÍ∞ÅÏù¥ Îì§ Í≤É Í∞ôÏäµÎãàÎã§. ÏÇ¨Ï†ÑÏ†êÍ≤ÄÏùÑ Ï≤†Ï†ÄÌûà ÌïòÎèÑÎ°ù ÌïòÍ≤†ÏäµÎãàÎã§. ÌïòÏó¨Í∞Ñ ÏàòÌï¥ÌïòÍ≥† ÎçîÍµ∞Îã§ÎÇò ÏΩîÎ°úÎÇòÎ°ú Ïñ¥Î†§ÏõÄÏùÑ ÍµâÏû•Ìûà ÎßéÏù¥ Í≤™Í≥† Í≥ÑÏãúÎäîÎç∞ Í∞ÄÎä•ÌïòÎ©¥ Ïù¥Îü∞ Î∂ÄÎ∂ÑÎì§ÏùÑ Ï∂©Î∂ÑÌûà Í≤ÄÌÜ†Ìï¥ÏÑú ÏóÖÎ¨¥Î•º Ï∂îÏßÑÌï¥ Ï£ºÏãúÍ∏∞Î•º Î∂ÄÌÉÅÎìúÎ¶¨Î©¥ÏÑú ÎßàÏπòÍ≤†ÏäµÎãàÎã§. Í≥†ÎßôÏäµÎãàÎã§. Í≥†ÎßôÏäµÎãàÎã§. Îòê ÏßàÏùòÌïòÏã§ ÏùòÏõêÎãò Í≥ÑÏã≠ÎãàÍπå? ÏßàÏùòÌïòÏã§ ÏùòÏõêÎãòÏù¥ Ïïà Í≥ÑÏãúÎØÄÎ°ú ÏßàÏùò„ÜçÎãµÎ≥ÄÏùÑ ÎßàÏπòÍ≤†ÏäµÎãàÎã§. Ï∂ïÏÇ∞ÏãùÌíàÍ≥ºÏû•Îãò ÏàòÍ≥†ÌïòÏÖ®ÏäµÎãàÎã§. Ïù¥ÏÉÅÏúºÎ°ú Ïò§ÎäòÏùò Í≥ÑÌöçÎêú ÏùòÏÇ¨ÏùºÏ†ïÏùÑ Î™®Îëê ÎßàÏπòÎ©∞, 8Ïõî 27Ïùº Î™©ÏöîÏùº Ïò§Ï†Ñ 10Ïãú Ï†ú3Ï∞® Î≥∏ÌöåÏùòÏóêÏÑúÎäî ÏÇ∞Î¶ºÎÖπÏßÄÍ≥º Ïô∏ 6Í∞ú Î∂ÄÏÑúÏùò Ï£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ Î≥¥Í≥†Î•º Îì£Í≤†ÏäµÎãàÎã§. Îã§Î•∏ ÏùòÍ≤¨Ïù¥ ÏóÜÏúºÏãúÎ©¥ Ï†ú327Ìöå ÏùåÏÑ±Íµ∞ÏùòÌöå ÏûÑÏãúÌöå Ï†ú2Ï∞® Î≥∏ÌöåÏùòÎ•º Î™®Îëê ÎßàÏπòÍ≥†Ïûê Ìï©ÎãàÎã§. ÏùòÏõê Ïó¨Îü¨Î∂Ñ! Îã§Î•∏ ÏùòÍ≤¨ ÏóÜÏúºÏã≠ÎãàÍπå? („ÄåÏóÜÏäµÎãàÎã§„ÄçÌïòÎäî ÏùòÏõê ÏûàÏùå) Îã§Î•∏ ÏùòÍ≤¨Ïù¥ ÏóÜÏúºÎØÄÎ°ú ÏÇ∞ÌöåÎ•º ÏÑ†Ìè¨Ìï©ÎãàÎã§. (14Ïãú40Î∂Ñ ÏÇ∞Ìöå)',\n"," 'summary': ['ÎÜçÏ∂ï ÏÜåÍ¥Ä 2020ÎÖÑÎèÑ Íµ∞Ï†ïÏ£ºÏöî ÌòÑÏïàÏÇ¨ÏóÖ Î≥¥Í≥†.',\n","  'ÏÑúÌö®ÏÑù ÏùòÏõêÏùÄ Ìá¥ÎπÑÎ∂ÄÏàôÎèÑ Í≤ÄÏÇ¨ ÏùòÎ¨¥Ìôî ÏßÄÏõêÏÇ¨ÏóÖ Ï§ë ÏùºÎ∂Ä ÎßàÎ¶øÏàòÍ∞Ä ÏùåÏÑ±Íµ∞ ÌïúÏö∞ Î∏åÎûúÎìúÍ∞Ä Îê† Ïàò ÏûàÎèÑÎ°ù ÎÖ∏Î†•Ìï¥Ï§Ñ Í≤ÉÏùÑ ÏöîÏ≤≠Ìï®.',\n","  'ÏπúÌôòÍ≤Ω Î°úÏª¨Ìë∏Îìú Îß§Ïû•Ïùò Í≤ΩÏö∞ Í¥ÄÎÇ¥ ÏÉùÏÇ∞ ÎÜçÏÇ∞Î¨ºÏùÑ ÏúÑÏ£ºÎ°úÎßå ÌåêÎß§ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê ÏùåÏÑ±Íµ∞ Í≥†Ï∂ßÍ∞ÄÎ£®Î•º Ï†ÅÍ∑πÏ†ÅÏúºÎ°ú ÌôçÎ≥¥Ìï† Í≤É.',\n","  'ÏùåÏÑ±ÏÇ∞ ÎÜçÏÇ∞Î¨ºÏùò Í≤ΩÏö∞ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÍ≥º Í≥µÍ∏âÎêòÎäî Î¨ºÎüâÏùò ÏñëÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùò ÏñëÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî Î¨ºÎüâÏùÑ Í∞êÏïàÌïòÏó¨ ÏùåÏÑ±Íµ∞ÏóêÏÑú Í≥µÍ∏âÌïòÎäî']}"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6xGM31Lw97P","executionInfo":{"status":"ok","timestamp":1633258296999,"user_tz":-540,"elapsed":642,"user":{"displayName":"Ïù¥ÌòÑÌò∏","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06707352264141706061"}},"outputId":"b1cf860d-67d0-4086-ee11-c939db046379"},"source":["test_dataset[199][\"input_ids\"][1]"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([14074, 16469, 14581, 13590, 14262, 14426, 14033, 17054, 14543,\n","       14955, 14549, 14734, 14340, 27269, 14025, 19050, 20706, 15693,\n","       15118, 11264, 14199, 21993,  9173, 28640,  9866, 22804, 15543,\n","       15693, 14466, 14032, 15489,  9475, 14605, 17939, 14088, 21888,\n","        9264, 25490, 14562, 14487, 14285, 17149, 14246, 21763, 18193,\n","       14303, 14214, 11911, 10184, 13590, 11911, 14025, 12471,  9866,\n","       14972, 14056, 19867, 14303, 14596, 13676, 25899, 22245, 12007,\n","       15709, 16467, 14088, 14543, 22456, 21702, 18656, 15176, 14938,\n","       16334, 14605, 14669, 14528, 15332, 14199, 29072, 17208,  9120,\n","       14030, 14605, 23928, 29334, 14034, 14704, 14088, 21888,  9264,\n","       25490, 14562, 14334, 14177, 29883, 14333, 16669, 14153, 25925,\n","       26638, 14410,  9743, 14158, 11478, 27879, 14092, 13744, 11265,\n","       14410,  9743, 25925, 13607, 21888,  9264, 25490, 14562, 23433,\n","        9743, 16345, 23111, 14490, 18940, 15217,  9102, 14032,  9102,\n","       13586, 11478, 14562, 14308, 12471, 28530, 25925, 17770, 29883,\n","       15484, 11028, 10948, 11373,  9866, 17535, 17130, 13714, 14423,\n","       14573, 14334, 14432, 27449, 14304, 14042, 17691, 14972, 14062,\n","       11373,  9866, 18547, 14634, 24301, 15709, 14182,   252, 13699,\n","       14747, 21045, 14117, 18764, 26908, 20604, 16158, 23855, 24789,\n","       15078, 18058, 13590, 16605, 21464, 17784, 14974, 17214, 18691,\n","       15220, 15459, 15129, 15364,  9698, 27915, 15679, 14502, 14062,\n","       11373,  9866,  9039, 14527, 18102, 15131, 20470, 17535,  9264,\n","       17035, 20628, 15037, 26393, 16869, 17535, 13590, 14494, 14308,\n","       23286, 14333, 14350, 17242, 15743, 20628, 14475, 15109, 21122,\n","       18778, 16593, 17427, 14026, 27927, 15472, 15694, 11264, 14236,\n","       14262, 18691, 14285, 16707, 15292, 18799, 14290, 14643, 10370,\n","       10443, 16546, 14308, 23286, 14333, 18778, 16593, 17427, 20628,\n","       20757,  9039, 15798, 15321, 14118, 12244,   262, 14285, 16707,\n","       15292, 18799, 18102, 15131, 20470, 20418, 10443, 14236, 27944,\n","       14285, 16707, 16960, 28559, 13607,  9001,  9102, 18799, 14723,\n","       14042, 11467, 14090, 15914, 12034, 11465, 12244,   262, 14858,\n","       14955, 17032, 22611, 14220,  9584, 14150, 17130, 19410, 14027,\n","       15097, 18900, 14158,  9866, 28842, 17050, 14158, 14704, 14334,\n","       13586, 22344, 19682, 24789, 10386, 10213, 24681, 14593, 14135,\n","       25894, 17517, 18194,  9475, 15109, 17939, 14088, 16518,  9102,\n","       14543, 14787, 12471, 28530, 17820, 16611, 14573, 14779, 15709,\n","       14584,  9102, 22299, 14059, 15933, 18664, 14036, 15634,  9925,\n","       14455, 17887, 18764, 14443,   236, 14455, 14036, 14033, 22802,\n","       14584,  9102, 11747, 15028, 17508, 22486, 14076,  9495, 17784,\n","       14446, 18251, 14605, 20628, 15037, 26393, 17808, 14087, 10488,\n","       15208, 15920, 12034, 14105, 15743, 20628, 15634, 23735, 14475,\n","       14082, 21240, 16719, 17997, 14032, 22802,  9866, 16759, 14446,\n","       15344, 16343, 17195, 14972, 17508, 14209, 24695, 14033, 14163,\n","       15170, 14747, 14209, 24695, 14261, 17685, 18525, 21464, 17784,\n","       14446, 18068, 16427, 16118, 26025, 14033, 23014, 14432, 15332,\n","       14584,  9102, 11747, 15188, 14794, 14719, 14082, 24955, 10500,\n","       23886, 14432, 29565, 16118,  8981, 14105, 15743, 16269, 14379,\n","       17569, 14209, 17033, 14562, 26393, 22255, 14593, 25898, 11028,\n","        9495, 14032,  9770, 14293, 14374, 18869, 14672, 16118, 26025,\n","       14033, 22519, 17442, 16467, 14432, 14609, 15914, 12034, 11467,\n","        8981, 17784, 17820, 16892, 14058, 25810, 15709, 14028, 17972,\n","       22245, 14668, 14432, 20628, 14177, 29883, 16371,  8985, 17032,\n","       18068, 15386, 10500, 15766, 14446, 14087, 10488, 15026, 17508,\n","       14467, 14033, 22802, 14440, 20662, 15055, 13619, 14477, 14365,\n","       14368, 14466, 14033, 22802, 14246, 14310, 21914, 17508, 19015,\n","       11264, 15987, 25925,  9989, 10325, 15170, 14166, 17939, 14432,\n","       15911, 14668, 14028, 20552, 14634, 12034, 14466, 14032])"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"_x71r-3QZbyp"},"source":[""],"execution_count":null,"outputs":[]}]}